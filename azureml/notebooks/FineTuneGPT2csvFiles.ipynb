{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01985119",
   "metadata": {},
   "source": [
    "# Installing Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab91db4",
   "metadata": {},
   "source": [
    "In order to get started, we will install the libraries in `requirements.txt` that we will use to load any pretrained huggingface model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6041f93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1408d79",
   "metadata": {},
   "source": [
    "# Preparing data in csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd08d033",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset banking77 (/home/azureuser/.cache/huggingface/datasets/banking77/default/1.1.0/aec0289529599d4572d76ab00c8944cb84f88410ad0c9e7da26189d31f62a55b)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"banking77\")\n",
    "\n",
    "train_dataset = raw_datasets[\"train\"]\n",
    "eval_dataset = raw_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39dc9d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.DataFrame()\n",
    "eval_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "for i in train_dataset:\n",
    "    train_df = train_df.append(i, ignore_index=True)\n",
    "\n",
    "for i in eval_dataset:\n",
    "    eval_df = eval_df.append(i, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc7622a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>I am still waiting on my card?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.0</td>\n",
       "      <td>What can I do if my card still hasn't arrived ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.0</td>\n",
       "      <td>I have been waiting over a week. Is the card s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0</td>\n",
       "      <td>Can I track my card while it is in the process...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>How do I know if I will get my card, or if it ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0   11.0                     I am still waiting on my card?\n",
       "1   11.0  What can I do if my card still hasn't arrived ...\n",
       "2   11.0  I have been waiting over a week. Is the card s...\n",
       "3   11.0  Can I track my card while it is in the process...\n",
       "4   11.0  How do I know if I will get my card, or if it ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afe492de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>How do I locate my card?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.0</td>\n",
       "      <td>I still have not received my new card, I order...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.0</td>\n",
       "      <td>I ordered a card but it has not arrived. Help ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0</td>\n",
       "      <td>Is there a way to know when my card will arrive?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>My card has not arrived yet.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0   11.0                           How do I locate my card?\n",
       "1   11.0  I still have not received my new card, I order...\n",
       "2   11.0  I ordered a card but it has not arrived. Help ...\n",
       "3   11.0   Is there a way to know when my card will arrive?\n",
       "4   11.0                       My card has not arrived yet."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a37b4c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"../data/train.csv\", index=False)\n",
    "eval_df.to_csv(\"../data/eval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73904d22",
   "metadata": {},
   "source": [
    "# Experiment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c697a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing Parameters\n",
    "preprocessing_num_workers = None #The number of processes to use for the preprocessing.\n",
    "overwrite_cache = True # Overwrite the cached training and evaluation sets.\n",
    "\n",
    "# Training Parameters\n",
    "max_train_samples = None #For debugging purposes or quicker training, truncate the number of training examples to this value if set.\n",
    "max_eval_samples = None #For debugging purposes or quicker training, truncate the number of evaluation examples to this value if set.\n",
    "model_name = \"gpt2\"\n",
    "output_dir = \"outputcsvFiles\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0b6ca3",
   "metadata": {},
   "source": [
    "# Load dataset\n",
    "\n",
    "We will use a small dataset for testing purposes. \n",
    "\n",
    "Dataset `banking77` composed of online banking queries annotated with their corresponding intents.\n",
    "\n",
    "`banking77` dataset provides a very fine-grained set of intents in a banking domain. It comprises 13,083 customer service queries labeled with 77 intents. \n",
    "\n",
    "For our purpose, we will ignore the intent label and focus on generating texts from the banking domain.\n",
    "\n",
    "**In this notebook, the dataset is already saved in csv files. We'll load the dataset from there!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3de46b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-86eb0fae5e1c7c0e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/azureuser/.cache/huggingface/datasets/csv/default-86eb0fae5e1c7c0e/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/azureuser/.cache/huggingface/datasets/csv/default-86eb0fae5e1c7c0e/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset('csv', data_files={'train': '../data/train.csv', 'test': '../data/eval.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fc04f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 10003\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 3080\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf5dda28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('label', [24.0]), ('text', ['Which countries do you operate in'])])\n",
      "OrderedDict([('label', [56.0]), ('text', ['I would like to refill my account using SWIFT.'])])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "index = random.sample(range(len(raw_datasets[\"train\"])), 1)\n",
    "print(raw_datasets[\"train\"][index])\n",
    "\n",
    "index = random.sample(range(len(raw_datasets[\"test\"])), 1)\n",
    "print(raw_datasets[\"test\"][index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a182503",
   "metadata": {},
   "source": [
    "# Preprocess & Tokenize Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c31f505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoTokenizer\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "text_column_name = \"text\"\n",
    "column_names = raw_datasets[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79e7f20",
   "metadata": {},
   "source": [
    "## Preprocess Dataset & add eos_token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83d7fa87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c55a03767445b9bf4606de3e1e1b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding eos_token to each example in the dataset:   0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ff8546b0c594d9a83995da7d489a8cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding eos_token to each example in the dataset:   0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Main data processing function that will add eos_token to each text in the dataset\n",
    "def add_eos_token(examples):\n",
    "    examples_with_eos = examples\n",
    "    examples_with_eos[text_column_name] = [x + tokenizer.eos_token for x in examples[text_column_name]]  \n",
    "    return examples_with_eos\n",
    "\n",
    "raw_datasets = raw_datasets.map(\n",
    "    add_eos_token,\n",
    "    batched=True,\n",
    "    num_proc=preprocessing_num_workers,\n",
    "    load_from_cache_file=not overwrite_cache,\n",
    "    desc=f\"Adding eos_token to each example in the dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c39a8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('label', [49.0]), ('text', ['After inputting the wrong pin too many times, can you now help me unblock my pin?<|endoftext|>'])])\n"
     ]
    }
   ],
   "source": [
    "index = random.sample(range(len(raw_datasets[\"train\"])), 1)\n",
    "\n",
    "print(raw_datasets[\"train\"][index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b301028",
   "metadata": {},
   "source": [
    "## Tokenize dataset using gpt2 tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0084bf9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc2de6caff5462782885f5aae8dc81b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23f5fff93f749eeb0853d900a3fbc17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[text_column_name])\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    num_proc=preprocessing_num_workers,\n",
    "    remove_columns=column_names,\n",
    "    load_from_cache_file=not overwrite_cache,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "029faa62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('label', [0.0]), ('text', ['Can I activate my card?<|endoftext|>'])])\n",
      "OrderedDict([('attention_mask', [[1, 1, 1, 1, 1, 1, 1]]), ('input_ids', [[6090, 314, 15155, 616, 2657, 30, 50256]])])\n"
     ]
    }
   ],
   "source": [
    "index = random.sample(range(len(raw_datasets[\"train\"])), 1)\n",
    "\n",
    "print(raw_datasets[\"train\"][index])\n",
    "print(tokenized_datasets[\"train\"][index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9628c3b",
   "metadata": {},
   "source": [
    "# Concatenate all texts from our dataset and generate chunks of block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "640a8f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d8b5789838f45ea83c3961d84164e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Grouping texts in chunks of 1024:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88413c36e2654f05a584cbd7e097fa38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Grouping texts in chunks of 1024:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "block_size = tokenizer.model_max_length\n",
    "if block_size > 1024:\n",
    "    # The tokenizer picked seems to have a very large `model_max_length`\n",
    "    block_size = 1024\n",
    "\n",
    "# Main data processing function that will concatenate all texts from our dataset and generate chunks of block_size.\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "    # customize this part to your needs.\n",
    "    if total_length >= block_size:\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=len(tokenized_datasets[\"train\"]), # if training size is very small, like in our case.\n",
    "    num_proc=preprocessing_num_workers,\n",
    "    load_from_cache_file=not overwrite_cache,\n",
    "    desc=f\"Grouping texts in chunks of {block_size}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3b70be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 11.0, 'text': 'I am still waiting on my card?<|endoftext|>'}\n",
      "{'label': 11.0, 'text': \"What can I do if my card still hasn't arrived after 2 weeks?<|endoftext|>\"}\n",
      "{'label': 11.0, 'text': 'I have been waiting over a week. Is the card still coming?<|endoftext|>'}\n",
      "{'label': 11.0, 'text': 'Can I track my card while it is in the process of delivery?<|endoftext|>'}\n"
     ]
    }
   ],
   "source": [
    "print(raw_datasets[\"train\"][0])\n",
    "print(raw_datasets[\"train\"][1])\n",
    "print(raw_datasets[\"train\"][2])\n",
    "print(raw_datasets[\"train\"][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecc2dad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [40, 716, 991, 4953, 319, 616, 2657, 30, 50256]}\n",
      "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [2061, 460, 314, 466, 611, 616, 2657, 991, 5818, 470, 5284, 706, 362, 2745, 30, 50256]}\n",
      "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [40, 423, 587, 4953, 625, 257, 1285, 13, 1148, 262, 2657, 991, 2406, 30, 50256]}\n",
      "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [6090, 314, 2610, 616, 2657, 981, 340, 318, 287, 262, 1429, 286, 7585, 30, 50256]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_datasets[\"train\"][0])\n",
    "print(tokenized_datasets[\"train\"][1])\n",
    "print(tokenized_datasets[\"train\"][2])\n",
    "print(tokenized_datasets[\"train\"][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e9390b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 716, 991, 4953, 319, 616, 2657, 30, 50256, 2061, 460, 314, 466, 611, 616, 2657, 991, 5818, 470, 5284, 706, 362, 2745, 30, 50256, 40, 423, 587, 4953, 625, 257, 1285, 13, 1148, 262, 2657, 991, 2406, 30, 50256]\n"
     ]
    }
   ],
   "source": [
    "print(lm_datasets[\"train\"][0]['input_ids'][:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055d1673",
   "metadata": {},
   "source": [
    "# Prepare Training & Evaluation Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bb2833",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Recheck script train/eval datasets! It seems training data is split even if test set is provided!</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad3dcb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = lm_datasets[\"train\"]\n",
    "eval_dataset = lm_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43788af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if max_train_samples is not None:\n",
    "    train_dataset = train_dataset.select(range(max_train_samples))\n",
    "if max_eval_samples is not None:\n",
    "    eval_dataset = eval_dataset.select(range(max_eval_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a33570",
   "metadata": {},
   "source": [
    "# Set Logging Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5bb7d5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from importlib import reload  # Not needed in Python 2\n",
    "import logging\n",
    "reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.DEBUG, datefmt='%I:%M:%S')\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Log a few random samples from the training set:\n",
    "#for index in random.sample(range(len(train_dataset)), 3):\n",
    "    #logger.info(f\"Sample {index} of the training set: {train_dataset[index]}. \\n\")\n",
    "    #logger.info(f\"Sample {index} of the training set shape: {len(train_dataset[index]['input_ids'])}. \\n\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45d2538b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:44:06 DEBUG:Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
      "07:44:06 DEBUG:Creating converter from 7 to 5\n",
      "07:44:06 DEBUG:Creating converter from 5 to 7\n",
      "07:44:06 DEBUG:Creating converter from 7 to 5\n",
      "07:44:06 DEBUG:Creating converter from 5 to 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': <tf.Tensor: shape=(1, 1024), dtype=int64, numpy=array([[1, 1, 1, ..., 1, 1, 1]])>, 'input_ids': <tf.Tensor: shape=(1, 1024), dtype=int64, numpy=array([[ 307,  284,  779, ..., 1280, 1848,   13]])>, 'labels': <tf.Tensor: shape=(1, 1024), dtype=int64, numpy=array([[ 307,  284,  779, ..., 1280, 1848,   13]])>}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "index = random.sample(range(len(train_dataset)), 1)\n",
    "example = train_dataset[index]\n",
    "example = {key: tf.convert_to_tensor(arr, dtype_hint=tf.int64) for key, arr in example.items()}\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1114d4ed",
   "metadata": {},
   "source": [
    "# Check Training Parameters\n",
    "\n",
    "We can customize the training arguments using training_args if we want, or hypertune some on a seperate validation set (might take a huge amount of time though).\n",
    "\n",
    "For more arguments, check: https://huggingface.co/transformers/main_classes/trainer.html#transformers.TFTrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9aa46e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:44:08 INFO:PyTorch: setting up devices\n",
      "07:44:08 INFO:The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "07:44:08 INFO:Tensorflow: setting up strategy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'init_lr': 5e-05,\n",
       " 'num_replicas': 1,\n",
       " 'num_train_epochs': 3.0,\n",
       " 'per_device_train_batch_size': 8,\n",
       " 'batches_per_epoch': 18,\n",
       " 'num_train_steps': 54,\n",
       " 'num_warmup_steps': 0,\n",
       " 'adam_beta1': 0.9,\n",
       " 'adam_beta2': 0.999,\n",
       " 'adam_epsilon': 1e-08,\n",
       " 'weight_decay_rate': 0.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TFTrainingArguments\n",
    "\n",
    "training_args = TFTrainingArguments(output_dir=output_dir)\n",
    "\n",
    "num_replicas = training_args.strategy.num_replicas_in_sync\n",
    "batches_per_epoch = len(train_dataset) // (num_replicas * training_args.per_device_train_batch_size)\n",
    "\n",
    "{\n",
    "    \"init_lr\": training_args.learning_rate,\n",
    "    \"num_replicas\": num_replicas,\n",
    "    \"num_train_epochs\": training_args.num_train_epochs,\n",
    "    \"per_device_train_batch_size\": training_args.per_device_train_batch_size,\n",
    "    \"batches_per_epoch\": len(train_dataset) // (num_replicas * training_args.per_device_train_batch_size),\n",
    "    \"num_train_steps\": int(training_args.num_train_epochs * batches_per_epoch),\n",
    "    \"num_warmup_steps\": training_args.warmup_steps,\n",
    "    \"adam_beta1\": training_args.adam_beta1,\n",
    "    \"adam_beta2\": training_args.adam_beta2,\n",
    "    \"adam_epsilon\": training_args.adam_epsilon,\n",
    "    \"weight_decay_rate\": training_args.weight_decay\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60065bca",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "* Load Pretrained Model \n",
    "* Resize the number of token embeddings in the model to that of the tokenizer\n",
    "    * Since our model and tokenizer belong to the same model, the number of token embeddings should be the same.\n",
    "    \n",
    "* Generate tf.data.Dataset (s) Sample Generator:\n",
    "    * Reoreder batch randomly.\n",
    "    * Convert each tokenized text to a tensor.\n",
    " \n",
    "* Define a callback SavePretrainedCallback that will save the model checkpoint at the end of each epoch.\n",
    "\n",
    "* Define the neural network optimizer from the arguments set in the training_args!\n",
    "\n",
    "* Define the loss: We are using a dummy loss that will minimize the difference between predicted and real next token.\n",
    "    * There should be a smarter loss.\n",
    "\n",
    "* Fit the model over the training dataset & evaluate the model over the eval dataset.\n",
    "\n",
    "* Log the loss & the perplexity metric of the model.\n",
    "\n",
    "* Save the final model to the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3bf263f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:44:09 INFO:PyTorch: setting up devices\n",
      "07:44:09 INFO:The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "07:44:09 INFO:Tensorflow: setting up strategy\n",
      "07:44:09 INFO:loading weights file https://huggingface.co/gpt2/resolve/main/tf_model.h5 from cache at /home/azureuser/.cache/huggingface/transformers/4029f7287fbd5fa400024f6bbfcfeae9c5f7906ea97afcaaa6348ab7c6a9f351.723d8eaff3b27ece543e768287eefb59290362b8ca3b1c18a759ad391dca295a.h5\n",
      "07:44:12 WARNING:All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "07:44:12 WARNING:All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "07:44:12 INFO:***** Running training *****\n",
      "07:44:12 INFO:  Num examples = 144\n",
      "07:44:12 INFO:  Num Epochs = 3.0\n",
      "07:44:12 INFO:  Instantaneous batch size per device = 8\n",
      "07:44:12 INFO:  Total train batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:44:15 WARNING:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).07:44:17 WARNING:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f0f3a04f528>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: <cyfunction Socket.send at 0x7f0f53b51d90> is not a module, class, method, function, traceback, frame, or code object\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f0f3a04f528>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: <cyfunction Socket.send at 0x7f0f53b51d90> is not a module, class, method, function, traceback, frame, or code object\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "07:44:17 WARNING:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "07:44:18 WARNING:From /anaconda/envs/azureml_py36/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "07:44:25 WARNING:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "07:44:25 WARNING:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 2.4710 - loss_loss: 2.4710 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:54:53 WARNING:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "07:54:53 WARNING:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 797s 43s/step - loss: 2.4710 - loss_loss: 2.4710 - val_loss: 2.2002 - val_loss_loss: 2.2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:57:29 DEBUG:Creating converter from 5 to 3\n",
      "07:57:33 INFO:Model weights saved in outputcsvFiles/tf_model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3\n",
      "18/18 [==============================] - 810s 46s/step - loss: 2.1766 - loss_loss: 2.1766 - val_loss: 2.1226 - val_loss_loss: 2.1226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:11:07 INFO:Model weights saved in outputcsvFiles/tf_model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3\n",
      "18/18 [==============================] - 755s 42s/step - loss: 2.1224 - loss_loss: 2.1224 - val_loss: 2.1032 - val_loss_loss: 2.1032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:23:47 INFO:Model weights saved in outputcsvFiles/tf_model.h5\n",
      "08:23:47 INFO:  Final train loss: 2.122\n",
      "08:23:47 INFO:  Final train perplexity: 8.351\n",
      "08:23:47 INFO:  Final validation loss: 2.103\n",
      "08:23:47 INFO:  Final validation perplexity: 8.193\n",
      "08:23:51 INFO:Model weights saved in outputcsvFiles/tf_model.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from functools import partial\n",
    "from transformers import AutoConfig, TFAutoModelForCausalLM\n",
    "from transformers import create_optimizer\n",
    "\n",
    "def sample_generator(dataset, tokenizer):\n",
    "    # Trim off the last partial batch if present\n",
    "    sample_ordering = np.random.permutation(len(dataset))\n",
    "    for sample_idx in sample_ordering:\n",
    "        example = dataset[int(sample_idx)]\n",
    "        # Handle dicts with proper padding and conversion to tensor.\n",
    "        example = {key: tf.convert_to_tensor(arr, dtype_hint=tf.int64) for key, arr in example.items()}\n",
    "        yield example, example[\"labels\"]  # TF needs some kind of labels, even if we don't use them\n",
    "    return\n",
    "\n",
    "# region Helper classes\n",
    "class SavePretrainedCallback(tf.keras.callbacks.Callback):\n",
    "    # Hugging Face models have a save_pretrained() method that saves both the weights and the necessary\n",
    "    # metadata to allow them to be loaded as a pretrained model in future. This is a simple Keras callback\n",
    "    # that saves the model with this method after each epoch.\n",
    "    def __init__(self, output_dir, **kwargs):\n",
    "        super().__init__()\n",
    "        self.output_dir = output_dir\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.model.save_pretrained(self.output_dir)\n",
    "\n",
    "training_args = TFTrainingArguments(output_dir=output_dir)\n",
    "#training_args.per_device_train_batch_size = 32\n",
    "\n",
    "with training_args.strategy.scope():\n",
    "\n",
    "    config = AutoConfig.from_pretrained(model_name)\n",
    "    model = TFAutoModelForCausalLM.from_pretrained(model_name, config=config)\n",
    "\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    num_replicas = training_args.strategy.num_replicas_in_sync\n",
    "\n",
    "    # region TF Dataset preparation\n",
    "    train_generator = partial(sample_generator, train_dataset, tokenizer)\n",
    "    train_signature = {\n",
    "        feature: tf.TensorSpec(shape=(None,), dtype=tf.int64)\n",
    "        for feature in train_dataset.features\n",
    "        if feature != \"special_tokens_mask\"\n",
    "    }\n",
    "    train_sig = (train_signature, train_signature[\"labels\"])\n",
    "    options = tf.data.Options()\n",
    "    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
    "    tf_train_dataset = (\n",
    "        tf.data.Dataset.from_generator(train_generator, output_signature=train_sig)\n",
    "        .with_options(options)\n",
    "        .batch(batch_size=num_replicas * training_args.per_device_train_batch_size, drop_remainder=True)\n",
    "        .repeat(int(training_args.num_train_epochs))\n",
    "    )\n",
    "    eval_generator = partial(sample_generator, eval_dataset, tokenizer)\n",
    "    eval_signature = {\n",
    "        feature: tf.TensorSpec(shape=(None,), dtype=tf.int64)\n",
    "        for feature in eval_dataset.features\n",
    "        if feature != \"special_tokens_mask\"\n",
    "    }\n",
    "    eval_sig = (eval_signature, eval_signature[\"labels\"])\n",
    "    tf_eval_dataset = (\n",
    "        tf.data.Dataset.from_generator(eval_generator, output_signature=eval_sig)\n",
    "        .with_options(options)\n",
    "        .batch(batch_size=num_replicas * training_args.per_device_eval_batch_size, drop_remainder=True)\n",
    "        .repeat(int(training_args.num_train_epochs))\n",
    "    )\n",
    "    # endregion\n",
    "    # region Optimizer and loss\n",
    "    \n",
    "    batches_per_epoch = len(train_dataset) // (num_replicas * training_args.per_device_train_batch_size)\n",
    "    # Bias and layernorm weights are automatically excluded from the decay\n",
    "    optimizer, lr_schedule = create_optimizer(\n",
    "        init_lr=training_args.learning_rate,\n",
    "        num_train_steps=int(training_args.num_train_epochs * batches_per_epoch),\n",
    "        num_warmup_steps=training_args.warmup_steps,\n",
    "        adam_beta1=training_args.adam_beta1,\n",
    "        adam_beta2=training_args.adam_beta2,\n",
    "        adam_epsilon=training_args.adam_epsilon,\n",
    "        weight_decay_rate=training_args.weight_decay,\n",
    "    )\n",
    "\n",
    "    def dummy_loss(y_true, y_pred):\n",
    "        return tf.reduce_mean(y_pred)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss={\"loss\": dummy_loss})\n",
    "    # endregion\n",
    "\n",
    "    # region Training and validation\n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(f\"  Num examples = {len(train_dataset)}\")\n",
    "    logger.info(f\"  Num Epochs = {training_args.num_train_epochs}\")\n",
    "    logger.info(f\"  Instantaneous batch size per device = {training_args.per_device_train_batch_size}\")\n",
    "    logger.info(f\"  Total train batch size = {training_args.per_device_train_batch_size * num_replicas}\")\n",
    "\n",
    "    history = model.fit(\n",
    "        tf_train_dataset,\n",
    "        validation_data=tf_eval_dataset,\n",
    "        epochs=int(training_args.num_train_epochs),\n",
    "        steps_per_epoch=len(train_dataset) // (training_args.per_device_train_batch_size * num_replicas),\n",
    "        callbacks=[SavePretrainedCallback(output_dir=training_args.output_dir)],\n",
    "    )\n",
    "    try:\n",
    "        train_perplexity = math.exp(history.history[\"loss\"][-1])\n",
    "    except OverflowError:\n",
    "        train_perplexity = math.inf\n",
    "    try:\n",
    "        validation_perplexity = math.exp(history.history[\"val_loss\"][-1])\n",
    "    except OverflowError:\n",
    "        validation_perplexity = math.inf\n",
    "    logger.info(f\"  Final train loss: {history.history['loss'][-1]:.3f}\")\n",
    "    logger.info(f\"  Final train perplexity: {train_perplexity:.3f}\")\n",
    "    logger.info(f\"  Final validation loss: {history.history['val_loss'][-1]:.3f}\")\n",
    "    logger.info(f\"  Final validation perplexity: {validation_perplexity:.3f}\")\n",
    "    # endregion\n",
    "\n",
    "    if training_args.output_dir is not None:\n",
    "        model.save_pretrained(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e7d4cc",
   "metadata": {},
   "source": [
    "# Use Fine-tuned Model\n",
    "\n",
    "Now that we have trained our new language model on new data, lets give it a try! We will want to use the path to the directory that the script outputs the model file to, and load it up to see results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b29bd6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:23:51 INFO:loading weights file outputcsvFiles/tf_model.h5\n",
      "08:23:53 DEBUG:Creating converter from 3 to 5\n",
      "08:24:10 WARNING:All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "08:24:10 WARNING:All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at outputcsvFiles.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# setup imports to use the model\n",
    "from transformers import TFGPT2LMHeadModel\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "model = TFGPT2LMHeadModel.from_pretrained(output_dir)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9c2dc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:35:34 WARNING:Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: My card has been stolen. I need money. Thank you for the statement from the bank. If I forget that I did a transaction, would you\n",
      "2: My card gets locked when I go into my account, and I have a few minutes before I need to leave due to unexpected security rules. Can I\n",
      "3: My card was charged some time ago but it never returned, this will cost again\n",
      "4: My card is on file now.\n",
      "5: My card was charged but it was just taken out of my hand!\" The guy just said, \"Sorry, I thought you were charged. I would\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(\"My card\", return_tensors='tf')\n",
    "\n",
    "generated_text_samples = model.generate(\n",
    "    input_ids, \n",
    "    max_length=30,  \n",
    "    num_return_sequences=5,\n",
    "    no_repeat_ngram_size=2,\n",
    "    #repetition_penalty=1.5,\n",
    "    #top_p=0.92,\n",
    "    #temperature=.85,\n",
    "    do_sample=True,\n",
    "    #top_k=125,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "#Print output for each sequence generated above\n",
    "for i, beam in enumerate(generated_text_samples):\n",
    "  print(\"{}: {}\".format(i + 1,tokenizer.decode(beam, skip_special_tokens=True)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
