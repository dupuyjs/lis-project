{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "650eb732",
   "metadata": {},
   "source": [
    "# Create Datastore\n",
    "\n",
    "Create Datastore that connects to Azure blob container that contains raw text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad2041f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Datastore\n",
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# Register a new datastore from blob container with raw data\n",
    "blob_store = Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                                  datastore_name='lis_artifacts', \n",
    "                                                  container_name='lis-artifacts',\n",
    "                                                  account_name='lisml8132196936',\n",
    "                                                  account_key='vhUtGVMoHyzG0NBy86EkG+WYjXUfTiDxhDZvy4mJr2I5e432Lq1ynpyXMAP5z6fxK2Zf/woO8L2n1FJIThx1lA==')\n",
    "\n",
    "blob_store = Datastore.get(ws, datastore_name='lis_artifacts')\n",
    "\n",
    "ws.set_default_datastore('lis_artifacts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0651c273",
   "metadata": {},
   "source": [
    "Upload csv files to datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a96af5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 2 files\n",
      "Target already exists. Skipping upload for data/train.csv\n",
      "Target already exists. Skipping upload for data/eval.csv\n",
      "Uploaded 0 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_0481918fc0914cb9939dc3d743fe069c"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload the local files from src_dir to the datastore\n",
    "\n",
    "blob_store.upload_files(files=['../data/train.csv', '../data/eval.csv'], target_path='data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20edee9",
   "metadata": {},
   "source": [
    "# Create Components Directories\n",
    "\n",
    "Create a directory for the components of the pipeline. Create subdirectories for each component/step (train, register, deploy ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b752d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "# Set the directory for the experiment files \n",
    "components_dir = 'lis_components'\n",
    "os.makedirs(components_dir, exist_ok=True)\n",
    "\n",
    "# Create a directory inside for the train component\n",
    "os.makedirs(os.path.join(components_dir, \"train\"), exist_ok=True)\n",
    "# Create a directory inside for the register component\n",
    "os.makedirs(os.path.join(components_dir, \"register\"), exist_ok=True)\n",
    "# Create a directory inside for the deploy component\n",
    "os.makedirs(os.path.join(components_dir, \"deploy\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb3fc0c",
   "metadata": {},
   "source": [
    "# Step 1: train.py\n",
    "\n",
    "This script train load a pretrained GPT2 model and fine tune the model over the train & eval datasets provided in the datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fa03c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lis_components/train/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $components_dir/train/train.py\n",
    "\n",
    "import random\n",
    "import logging\n",
    "from importlib import reload  # Not needed in Python 2\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from functools import partial\n",
    "\n",
    "from transformers import TFTrainingArguments, HfArgumentParser\n",
    "from transformers import AutoConfig, AutoTokenizer\n",
    "from transformers import TFAutoModelForCausalLM\n",
    "from transformers import create_optimizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "from azureml.core import Run\n",
    "\n",
    "#reload(logging)\n",
    "#logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.DEBUG, datefmt='%I:%M:%S')\n",
    "#logger = logging.getLogger()\n",
    "\n",
    "\n",
    "# region Command-line arguments\n",
    "@dataclass\n",
    "class ModelArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune, or train from scratch.\n",
    "    \"\"\"\n",
    "\n",
    "    model_name: str = field(\n",
    "        default=\"gpt2\",\n",
    "        metadata={\n",
    "            \"help\": \"The model checkpoint for weights initialization.\"\n",
    "        },\n",
    "    )\n",
    "        \n",
    "    def __post_init__(self):\n",
    "        if self.model_name is None:\n",
    "            raise ValueError(\n",
    "                \"--cannot call script without model_name argument\"\n",
    "            )\n",
    "\n",
    "@dataclass\n",
    "class DataTrainingArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
    "    \"\"\"\n",
    "\n",
    "    train_file: str = field(default=\"data/train.csv\", metadata={\"help\": \"The input training data file (a csv file).\"})\n",
    "    eval_file: str = field(\n",
    "        default=\"data/eval.csv\",\n",
    "        metadata={\"help\": \"The input evaluation data file to evaluate the perplexity on (a csv file).\"},\n",
    "    )\n",
    "    overwrite_cache: bool = field(\n",
    "        default=True, metadata={\"help\": \"Overwrite the cached training and evaluation sets\"}\n",
    "    )\n",
    "    preprocessing_num_workers: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"The number of processes to use for the preprocessing.\"},\n",
    "    )\n",
    "    max_train_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n",
    "            \"value if set.\"\n",
    "        },\n",
    "    )\n",
    "    max_eval_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n",
    "            \"value if set.\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.train_file is None or self.eval_file is None:\n",
    "            raise ValueError(\n",
    "                \"--cannot call scripts without train_file & eval_file arguments\"\n",
    "            )\n",
    "\n",
    "def sample_generator(dataset, tokenizer):\n",
    "    # Trim off the last partial batch if present\n",
    "    sample_ordering = np.random.permutation(len(dataset))\n",
    "    for sample_idx in sample_ordering:\n",
    "        example = dataset[int(sample_idx)]\n",
    "        # Handle dicts with proper padding and conversion to tensor.\n",
    "        example = {key: tf.convert_to_tensor(arr, dtype_hint=tf.int64) for key, arr in example.items()}\n",
    "        yield example, example[\"labels\"]  # TF needs some kind of labels, even if we don't use them\n",
    "    return\n",
    "\n",
    "# region Helper classes\n",
    "class SavePretrainedCallback(tf.keras.callbacks.Callback):\n",
    "    # Hugging Face models have a save_pretrained() method that saves both the weights and the necessary\n",
    "    # metadata to allow them to be loaded as a pretrained model in future. This is a simple Keras callback\n",
    "    # that saves the model with this method after each epoch.\n",
    "    def __init__(self, output_dir, **kwargs):\n",
    "        super().__init__()\n",
    "        self.output_dir = output_dir\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.model.save_pretrained(self.output_dir)\n",
    "        \n",
    "        \n",
    "def main():\n",
    "    # region Argument Parsing\n",
    "    parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TFTrainingArguments))\n",
    "\n",
    "    # region Setup logging\n",
    "    #logger.setLevel(logging.INFO)\n",
    "    \n",
    "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
    "\n",
    "    # Load the dataset from the datastore.\n",
    "    raw_datasets = load_dataset('csv', data_files={'train': data_args.train_file, 'test': data_args.eval_file})\n",
    "\n",
    "    # Testing loading datasets\n",
    "    index = random.sample(range(len(raw_datasets[\"train\"])), 1)\n",
    "    #logger.info(f\"  Example raw dataset: %s\", raw_datasets[\"train\"][index])\n",
    "\n",
    "    # Load pretrained model and tokenizer\n",
    "    \n",
    "    config = AutoConfig.from_pretrained(model_args.model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_args.model_name)\n",
    "\n",
    "    text_column_name = \"text\"\n",
    "    column_names = raw_datasets[\"train\"].column_names\n",
    "    \n",
    "    # Preprocess Dataset & add eos_token \n",
    "    # Main data processing function that will add eos_token to each text in the dataset\n",
    "    def add_eos_token(examples):\n",
    "        examples_with_eos = examples\n",
    "        examples_with_eos[text_column_name] = [x + tokenizer.eos_token for x in examples[text_column_name]]  \n",
    "        return examples_with_eos\n",
    "\n",
    "    raw_datasets = raw_datasets.map(\n",
    "        add_eos_token,\n",
    "        batched=True,\n",
    "        num_proc=data_args.preprocessing_num_workers,\n",
    "        load_from_cache_file=not data_args.overwrite_cache,\n",
    "        desc=f\"Adding eos_token to each example in the dataset\",\n",
    "    )\n",
    "    \n",
    "    # Testing preprocess\n",
    "    #logger.info(f\"  Example raw dataset with eos token: %s\", raw_datasets[\"train\"][index])\n",
    "\n",
    "    ## Tokenize dataset using gpt2 tokenizer\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[text_column_name])\n",
    "\n",
    "    tokenized_datasets = raw_datasets.map(\n",
    "        tokenize_function,\n",
    "        batched=True,\n",
    "        num_proc=data_args.preprocessing_num_workers,\n",
    "        remove_columns=column_names,\n",
    "        load_from_cache_file=not data_args.overwrite_cache,\n",
    "        desc=\"Running tokenizer on dataset\",\n",
    "    )\n",
    "    \n",
    "    # Testing Tokenization\n",
    "    #logger.info(f\"  Example tokenized dataset: %s\", tokenized_datasets[\"train\"][index])\n",
    "\n",
    "    # Concatenate all texts from our dataset and generate chunks of block_size\n",
    "    \n",
    "    block_size = tokenizer.model_max_length\n",
    "    if block_size > 1024:\n",
    "        # The tokenizer picked seems to have a very large `model_max_length`\n",
    "        block_size = 1024\n",
    "\n",
    "    # Main data processing function that will concatenate all texts from our dataset and generate chunks of block_size.\n",
    "    def group_texts(examples):\n",
    "        # Concatenate all texts.\n",
    "        concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "        total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "        # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "        # customize this part to your needs.\n",
    "        if total_length >= block_size:\n",
    "            total_length = (total_length // block_size) * block_size\n",
    "        # Split by chunks of max_len.\n",
    "        result = {\n",
    "            k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "            for k, t in concatenated_examples.items()\n",
    "        }\n",
    "        result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "        return result\n",
    "\n",
    "    lm_datasets = tokenized_datasets.map(\n",
    "        group_texts,\n",
    "        batched=True,\n",
    "        batch_size=len(tokenized_datasets[\"train\"]), # if training size is very small, like in our case.\n",
    "        num_proc=data_args.preprocessing_num_workers,\n",
    "        load_from_cache_file=not data_args.overwrite_cache,\n",
    "        desc=f\"Grouping texts in chunks of {block_size}\",\n",
    "    )\n",
    "    \n",
    "    # Testing Grouping Texts\n",
    "    \n",
    "    #logger.info(f\"  Example 0 raw dataset: %s\", raw_datasets[\"train\"][0])\n",
    "    #logger.info(f\"  Example 0 raw dataset: %s\", raw_datasets[\"train\"][1])\n",
    "    #logger.info(f\"  Example 0 raw dataset: %s\", raw_datasets[\"train\"][2])\n",
    "    #logger.info(f\"  Example 0 raw dataset: %s\", raw_datasets[\"train\"][3])\n",
    "\n",
    "    #logger.info(f\"  Example 0 tokenized dataset: %s\", tokenized_datasets[\"train\"][0])\n",
    "    #logger.info(f\"  Example 0 tokenized dataset: %s\", tokenized_datasets[\"train\"][1])\n",
    "    #logger.info(f\"  Example 0 tokenized dataset: %s\", tokenized_datasets[\"train\"][2])\n",
    "    #logger.info(f\"  Example 0 tokenized dataset: %s\", tokenized_datasets[\"train\"][3])\n",
    "\n",
    "   \n",
    "    #logger.info(f\"  Example 0 concatenated tokenized dataset: %s\", lm_datasets[\"train\"][0]['input_ids'][:40])\n",
    "\n",
    "    \n",
    "    # Prepare Training & Evaluation Datasets\n",
    "    train_dataset = lm_datasets[\"train\"]\n",
    "    eval_dataset = lm_datasets[\"test\"]\n",
    "    \n",
    "    if data_args.max_train_samples is not None:\n",
    "        train_dataset = train_dataset.select(range(data_args.max_train_samples))\n",
    "    if data_args.max_eval_samples is not None:\n",
    "        eval_dataset = eval_dataset.select(range(data_args.max_eval_samples))\n",
    "        \n",
    "    # Logging Training Parameters\n",
    "    \n",
    "    num_replicas = training_args.strategy.num_replicas_in_sync\n",
    "    batches_per_epoch = len(train_dataset) // (num_replicas * training_args.per_device_train_batch_size)\n",
    "    \"\"\"\n",
    "    logger.info(f\"  Training Arguments: %s\",\n",
    "    {\n",
    "        \"init_lr\": training_args.learning_rate,\n",
    "        \"num_replicas\": num_replicas,\n",
    "        \"strategy\": training_args.strategy,\n",
    "        \"num_train_epochs\": training_args.num_train_epochs,\n",
    "        \"per_device_train_batch_size\": training_args.per_device_train_batch_size,\n",
    "        \"batches_per_epoch\": len(train_dataset) // (num_replicas * training_args.per_device_train_batch_size),\n",
    "        \"num_train_steps\": int(training_args.num_train_epochs * batches_per_epoch),\n",
    "        \"num_warmup_steps\": training_args.warmup_steps,\n",
    "        \"adam_beta1\": training_args.adam_beta1,\n",
    "        \"adam_beta2\": training_args.adam_beta2,\n",
    "        \"adam_epsilon\": training_args.adam_epsilon,\n",
    "        \"weight_decay_rate\": training_args.weight_decay\n",
    "    }\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Train Model\n",
    "\n",
    "    with training_args.strategy.scope():\n",
    "\n",
    "        config = AutoConfig.from_pretrained(model_args.model_name)\n",
    "        model = TFAutoModelForCausalLM.from_pretrained(model_args.model_name, config=config)\n",
    "\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "        num_replicas = training_args.strategy.num_replicas_in_sync\n",
    "\n",
    "        # region TF Dataset preparation\n",
    "        train_generator = partial(sample_generator, train_dataset, tokenizer)\n",
    "        train_signature = {\n",
    "            feature: tf.TensorSpec(shape=(None,), dtype=tf.int64)\n",
    "            for feature in train_dataset.features\n",
    "            if feature != \"special_tokens_mask\"\n",
    "        }\n",
    "        train_sig = (train_signature, train_signature[\"labels\"])\n",
    "        options = tf.data.Options()\n",
    "        options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
    "        tf_train_dataset = (\n",
    "            tf.data.Dataset.from_generator(train_generator, output_signature=train_sig)\n",
    "            .with_options(options)\n",
    "            .batch(batch_size=num_replicas * training_args.per_device_train_batch_size, drop_remainder=True)\n",
    "            .repeat(int(training_args.num_train_epochs))\n",
    "        )\n",
    "        eval_generator = partial(sample_generator, eval_dataset, tokenizer)\n",
    "        eval_signature = {\n",
    "            feature: tf.TensorSpec(shape=(None,), dtype=tf.int64)\n",
    "            for feature in eval_dataset.features\n",
    "            if feature != \"special_tokens_mask\"\n",
    "        }\n",
    "        eval_sig = (eval_signature, eval_signature[\"labels\"])\n",
    "        tf_eval_dataset = (\n",
    "            tf.data.Dataset.from_generator(eval_generator, output_signature=eval_sig)\n",
    "            .with_options(options)\n",
    "            .batch(batch_size=num_replicas * training_args.per_device_eval_batch_size, drop_remainder=True)\n",
    "            .repeat(int(training_args.num_train_epochs))\n",
    "        )\n",
    "        # endregion\n",
    "        # region Optimizer and loss\n",
    "\n",
    "        batches_per_epoch = len(train_dataset) // (num_replicas * training_args.per_device_train_batch_size)\n",
    "        # Bias and layernorm weights are automatically excluded from the decay\n",
    "        optimizer, lr_schedule = create_optimizer(\n",
    "            init_lr=training_args.learning_rate,\n",
    "            num_train_steps=int(training_args.num_train_epochs * batches_per_epoch),\n",
    "            num_warmup_steps=training_args.warmup_steps,\n",
    "            adam_beta1=training_args.adam_beta1,\n",
    "            adam_beta2=training_args.adam_beta2,\n",
    "            adam_epsilon=training_args.adam_epsilon,\n",
    "            weight_decay_rate=training_args.weight_decay,\n",
    "        )\n",
    "\n",
    "        def dummy_loss(y_true, y_pred):\n",
    "            return tf.reduce_mean(y_pred)\n",
    "\n",
    "        model.compile(optimizer=optimizer, loss={\"loss\": dummy_loss})\n",
    "        # endregion\n",
    "\n",
    "        # region Training and validation\n",
    "        #logger.info(\"***** Running training *****\")\n",
    "        #logger.info(f\"  Num examples = {len(train_dataset)}\")\n",
    "        #logger.info(f\"  Num Epochs = {training_args.num_train_epochs}\")\n",
    "        #logger.info(f\"  Instantaneous batch size per device = {training_args.per_device_train_batch_size}\")\n",
    "        #logger.info(f\"  Total train batch size = {training_args.per_device_train_batch_size * num_replicas}\")\n",
    "\n",
    "        history = model.fit(\n",
    "            tf_train_dataset,\n",
    "            validation_data=tf_eval_dataset,\n",
    "            epochs=int(training_args.num_train_epochs),\n",
    "            steps_per_epoch=len(train_dataset) // (training_args.per_device_train_batch_size * num_replicas),\n",
    "            callbacks=[SavePretrainedCallback(output_dir=training_args.output_dir)],\n",
    "        )\n",
    "        try:\n",
    "            train_perplexity = math.exp(history.history[\"loss\"][-1])\n",
    "        except OverflowError:\n",
    "            train_perplexity = math.inf\n",
    "        try:\n",
    "            validation_perplexity = math.exp(history.history[\"val_loss\"][-1])\n",
    "        except OverflowError:\n",
    "            validation_perplexity = math.inf\n",
    "        #logger.info(f\"  Final train loss: {history.history['loss'][-1]:.3f}\")\n",
    "        #logger.info(f\"  Final train perplexity: {train_perplexity:.3f}\")\n",
    "        #logger.info(f\"  Final validation loss: {history.history['val_loss'][-1]:.3f}\")\n",
    "        #logger.info(f\"  Final validation perplexity: {validation_perplexity:.3f}\")\n",
    "        # endregion\n",
    "        \n",
    "        # log metrics to AML\n",
    "        run = Run.get_context()\n",
    "\n",
    "        run.log(\"Final train loss\", history.history['loss'][-1])\n",
    "        run.log(\"Final validation loss\", history.history['val_loss'][-1])\n",
    "        run.log(\"Final train perplexity\", train_perplexity)\n",
    "        run.log(\"Final validation perplexity\", validation_perplexity)\n",
    "\n",
    "        run.parent.log(\"Final train loss\", history.history['loss'][-1])\n",
    "        run.parent.log(\"Final validation loss\", history.history['val_loss'][-1])\n",
    "        run.parent.log(\"Final train perplexity\", train_perplexity)\n",
    "        run.parent.log(\"Final validation perplexity\", validation_perplexity)\n",
    "                \n",
    "        if training_args.output_dir is not None:\n",
    "            model.save_pretrained(training_args.output_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5787a186",
   "metadata": {},
   "source": [
    "# Step 2: register.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76eb543",
   "metadata": {},
   "source": [
    "This script uploads the saved h5 model from the blob store and register it as an AML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec9d0ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lis_components/register/register.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $components_dir/register/register.py\n",
    "\n",
    "# Import libraries\n",
    "import argparse\n",
    "from azureml.core import Run\n",
    "\n",
    "def main():\n",
    "    # Get parameters\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--model_dir', \n",
    "                        type=str, \n",
    "                        dest='model_dir', \n",
    "                        default=\"outputs\",\n",
    "                        help='model location')\n",
    "    parser.add_argument(\"--model_name\",\n",
    "                        type=str,\n",
    "                        help=\"Name of the Registered Model\",\n",
    "                        default=\"lis-gpt2-model\")\n",
    "    parser.add_argument(\"--register_deploy_link\",\n",
    "                        type=str,\n",
    "                        help=\"register_deploy_link\",\n",
    "                        default=\"register_deploy_link\")\n",
    "\n",
    "   \n",
    "    args = parser.parse_args()\n",
    "    model_dir = args.model_dir\n",
    "    model_name = args.model_name\n",
    "\n",
    "    # Get the experiment run context\n",
    "    run = Run.get_context()\n",
    "\n",
    "    # load the model\n",
    "    print(\"Loading model from \" + model_dir)\n",
    "    model_file = os.path.join(model_dir, \"tf_model.h5\")\n",
    "    model_config_file = os.path.join(model_dir, \"config.json\")\n",
    "\n",
    "    # Get metrics for registration\n",
    "    metrics = run.parent.get_metrics()\n",
    "\n",
    "    # Register the model\n",
    "    run.upload_file(\"outputs/tf_model.h5\", model_file)\n",
    "    run.upload_file(\"outputs/config.json\", model_config_file)\n",
    "    \n",
    "    run.register_model(\n",
    "        model_path=\"outputs/\",\n",
    "        model_name=model_name,\n",
    "        tags=metrics)\n",
    "\n",
    "    run.complete()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2787beb",
   "metadata": {},
   "source": [
    "# Step 3: deploy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90614822",
   "metadata": {},
   "source": [
    "This step needs two scripts:\n",
    "\n",
    "A script deploy.py that will use azureml api to deploy an ACIservice. \n",
    "\n",
    "A script score.py that will be used by the service to perform inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad4d32c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lis_components/deploy/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $components_dir/deploy/score.py\n",
    "\n",
    "import json\n",
    "from transformers import TFGPT2LMHeadModel\n",
    "from transformers import GPT2Tokenizer\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    ## TODO\n",
    "    global model, tokenizer\n",
    "    # Get the path to the deployed model file and load it\n",
    "    model_path = Model.get_model_path('lis-gpt2-model')    \n",
    "    model = TFGPT2LMHeadModel.from_pretrained(model_path)\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "\n",
    "    input_ids = tokenizer.encode(json.loads(raw_data)['data'], return_tensors='tf')\n",
    "\n",
    "    generated_text_samples = model.generate(\n",
    "        input_ids, \n",
    "        max_length=30,  \n",
    "        num_return_sequences=5,\n",
    "        no_repeat_ngram_size=2,\n",
    "        do_sample=True,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    json_output = {}\n",
    "    for i, beam in enumerate(generated_text_samples):\n",
    "        json_output[i+1] = tokenizer.decode(beam, skip_special_tokens=True)\n",
    "        \n",
    "    # Return the predictions as JSON\n",
    "    return json.dumps(json_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f279d858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lis_components/deploy/deploy.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $components_dir/deploy/deploy.py\n",
    "\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core import Run\n",
    "from azureml.core.model import Model\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "def main():\n",
    "    # Get parameters\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--service_name\",\n",
    "                        type=str,\n",
    "                        help=\"Name of the Web Service\",\n",
    "                        default=\"lis-gpt2-webservice\")\n",
    "    parser.add_argument(\"--model_name\",\n",
    "                        type=str,\n",
    "                        help=\"Name of the registered model name\",\n",
    "                        default=\"lis-gpt2-model\")\n",
    "    parser.add_argument(\"--cpu_cores\",\n",
    "                        type=int,\n",
    "                        help=\"CPU reserve capacity\",\n",
    "                        default=1)\n",
    "    parser.add_argument(\"--memory_gb\",\n",
    "                        type=float,\n",
    "                        help=\"Memory reserve capacity\",\n",
    "                        default=2)\n",
    "    parser.add_argument(\"--register_deploy_link\",\n",
    "                        type=str,\n",
    "                        help=\"register_deploy_link\",\n",
    "                        default=\"register_deploy_link\")\n",
    "    args = parser.parse_args()\n",
    "    service_name = args.service_name\n",
    "    model_name = args.model_name\n",
    "    cpu_cores = args.cpu_cores\n",
    "    memory_gb = args.memory_gb    \n",
    "    components_dir = \"lis_components\"\n",
    "    \n",
    "    # Configure the scoring environment\n",
    "    inference_config = InferenceConfig(runtime= \"python\",\n",
    "                                       entry_script=os.path.join(components_dir, \"deploy\", \"score.py\"),\n",
    "                                       conda_file=os.path.join(components_dir, \"dependencies_scoring.yml\"))\n",
    "\n",
    "    deployment_config = AciWebservice.deploy_configuration(cpu_cores = cpu_cores, memory_gb = memory_gb)\n",
    "    \n",
    "    # Get the experiment run context\n",
    "    run = Run.get_context()\n",
    "    ws = run.experiment.workspace\n",
    "    \n",
    "    model = ws.models[model_name]\n",
    "    print(model.name, 'version', model.version)\n",
    "\n",
    "    service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n",
    "\n",
    "    service.wait_for_deployment(True)\n",
    "    \n",
    "    print(service.state)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7251ae0c",
   "metadata": {},
   "source": [
    "# Create dependencies.yml\n",
    "\n",
    "Define an environment YAML file with the components steps script dependencies and create an Azure ML environment for the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bf3ca02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lis_components/dependencies.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $components_dir/dependencies.yml\n",
    "\n",
    "name: lis_env\n",
    "    \n",
    "dependencies:\n",
    "  # The python interpreter version.\n",
    "  # Currently Azure ML Workbench only supports 3.5.2 and later.\n",
    "  - python=3.6.9\n",
    "  - pip\n",
    "\n",
    "  - pip:\n",
    "      - transformers == 3.5.1\n",
    "      - datasets == 1.10.2\n",
    "      - tensorflow == 2.5.0\n",
    "      - azureml-defaults==1.30.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6c79ae",
   "metadata": {},
   "source": [
    "# Create dependencies_scoring.yml\n",
    "\n",
    "Define an environment YAML file with dependencies for the web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2400118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lis_components/dependencies_scoring.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $components_dir/dependencies_scoring.yml\n",
    "\n",
    "name: lis_env_scoring\n",
    "    \n",
    "dependencies:\n",
    "  # The python interpreter version.\n",
    "  # Currently Azure ML Workbench only supports 3.5.2 and later.\n",
    "  - python=3.6.9\n",
    "  - pip\n",
    "\n",
    "  - pip:\n",
    "      - transformers == 3.5.1\n",
    "      - tensorflow == 2.5.0\n",
    "      - azureml-defaults==1.30.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f543bcc",
   "metadata": {},
   "source": [
    "# Create an Azure Machine Learning Pipeline to Run the Scripts as a Pipeline¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c51b7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e832d466",
   "metadata": {},
   "source": [
    "## Prepare a Compute Environment for the Pipeline Steps\n",
    "\n",
    "Create a compute target for training your model. We use Azure ML managed compute (AmlCompute) for remote compute resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "727944cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"pipeline-cluster\"\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_NC6', max_nodes=2)\n",
    "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        pipeline_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da45cbb3",
   "metadata": {},
   "source": [
    "# Prepare Pipeline Envirnoment\n",
    "\n",
    "Prepare Pipeline environment, python dependencies & compute used by aml pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9044785b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline configuration created.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "# Create a Python environment for the pipeline experiment\n",
    "pipeline_environment = Environment.from_conda_specification(name = 'pipeline-env', \n",
    "                                                          file_path = os.path.join(components_dir, \n",
    "                                                                                   \"dependencies.yml\"))\n",
    "pipeline_environment.python.user_managed_dependencies = False # Let Azure ML manage dependencies\n",
    "pipeline_environment.docker.enabled = True # Use a docker container\n",
    "\n",
    "# Create a new runconfig object for the pipeline\n",
    "pipeline_run_config = RunConfiguration()\n",
    "\n",
    "# Use the compute you created above. \n",
    "pipeline_run_config.target = pipeline_cluster\n",
    "\n",
    "# Assign the environment to the run configuration\n",
    "pipeline_run_config.environment = pipeline_environment\n",
    "\n",
    "print (\"Pipeline configuration created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dc68389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.data import OutputFileDatasetConfig\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "\n",
    "# train_file, eval_file and output_file are passed as a datastore path between steps\n",
    "train_datastore_path = DataReference(data_reference_name = \"train_datastore_path\", datastore=ws.datastores['lis_artifacts'], path_on_datastore = \"data/train.csv\")\n",
    "eval_datastore_path = DataReference(data_reference_name = \"eval_datastore_path\", datastore=ws.datastores['lis_artifacts'], path_on_datastore = \"data/eval.csv\")\n",
    "output_datastore_path = OutputFileDatasetConfig(\"output_datastore_path\", destination=(ws.datastores['lis_artifacts'], \"outputs\")).as_mount()\n",
    "\n",
    "num_train_epochs_param = PipelineParameter(name=\"num_train_epochs\", default_value=3)\n",
    "\n",
    "aml_model_name_param = PipelineParameter(name=\"aml_model_name\", default_value=\"lis-gpt2-model\")\n",
    "register_deploy_link = PipelineData(\"register_deploy_link\")\n",
    "\n",
    "aml_service_name_param = PipelineParameter(name=\"aml_service_name\", default_value=\"lis-gpt2-serviceapp\")\n",
    "cpu_cores_param = PipelineParameter(name=\"cpu_cores\", default_value=1)\n",
    "memory_gb_param = PipelineParameter(name=\"memory_gb\", default_value=2)\n",
    "    \n",
    "    \n",
    "# Create Step 1, which runs the PythonScriptStep to train / finetune\n",
    "train_step = PythonScriptStep(name = \"Train\",\n",
    "                                source_directory = \".\",\n",
    "                                script_name = os.path.join(components_dir, \"train/train.py\"),\n",
    "                                arguments=['--model_name', \"gpt2\", \n",
    "                                           '--output_dir', output_datastore_path,\n",
    "                                           '--train_file', train_datastore_path,\n",
    "                                           '--eval_file', eval_datastore_path,\n",
    "                                           '--num_train_epochs', num_train_epochs_param,\n",
    "                                           #'--per_gpu_train_batch_size', 8,  \n",
    "                                           #'--per_gpu_eval_batch_size', 8, \n",
    "                                           #'--fp16'\n",
    "                                          ],\n",
    "                                inputs=[train_datastore_path, eval_datastore_path],\n",
    "                                compute_target = pipeline_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = False)\n",
    "\n",
    "# Create Step 2, which runs the PythonScriptStep to register model\n",
    "register_step = PythonScriptStep(name = \"Register\",\n",
    "                                source_directory = \".\",\n",
    "                                script_name = os.path.join(components_dir, \"register/register.py\"),\n",
    "                                arguments=['--model_name', aml_model_name_param, \n",
    "                                           '--model_dir', output_datastore_path.as_input(),\n",
    "                                           '--register_deploy_link', register_deploy_link\n",
    "                                          ],\n",
    "                                outputs=[register_deploy_link],\n",
    "                                compute_target = pipeline_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = False)\n",
    "\n",
    "# Create Step 3, which runs the PythonScriptStep to deploy model as a web service\n",
    "deploy_step = PythonScriptStep(name = \"Deploy\",\n",
    "                                source_directory = \".\",\n",
    "                                script_name = os.path.join(components_dir, \"deploy/deploy.py\"),\n",
    "                                arguments=['--service_name', aml_service_name_param, \n",
    "                                           '--model_name', aml_model_name_param, \n",
    "                                           '--cpu_cores', cpu_cores_param,\n",
    "                                           '--memory_gb', memory_gb_param,\n",
    "                                           '--register_deploy_link', register_deploy_link\n",
    "                                          ],\n",
    "                                inputs=[register_deploy_link],\n",
    "                                compute_target = pipeline_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d342b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline is built.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Construct the pipeline\n",
    "pipeline_steps = [train_step, register_step, deploy_step]\n",
    "pipeline = Pipeline(workspace = ws, steps=pipeline_steps)\n",
    "print(\"Pipeline is built.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82c4c666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step Train [9373786c][9f0b75a2-76b6-47e6-a8d3-19f505f6f2c5], (This step will run and generate new outputs)\n",
      "Created step Register [6992e5a1][348f6281-632d-4243-85c5-dfa0955d5980], (This step will run and generate new outputs)\n",
      "Created step Deploy [03a9787b][52116e00-bdf2-4f69-93c2-38c8d9179a2e], (This step will run and generate new outputs)\n",
      "Using data reference train_datastore_path for StepId [3e1ebfa3][ab4bddc8-5eb4-4709-ad5c-dc555df7d52f], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Using data reference eval_datastore_path for StepId [1ade389e][197693d2-331a-4bf3-a2b4-c18bf5d4bb63], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Submitted PipelineRun c61e6022-be86-4993-aaac-02f08f2d3152\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/c61e6022-be86-4993-aaac-02f08f2d3152?wsid=/subscriptions/2f091423-f84d-4062-8e67-1437a0c50045/resourcegroups/lis/workspaces/lis-ml&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "Pipeline submitted for execution.\n",
      "PipelineRunId: c61e6022-be86-4993-aaac-02f08f2d3152\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/c61e6022-be86-4993-aaac-02f08f2d3152?wsid=/subscriptions/2f091423-f84d-4062-8e67-1437a0c50045/resourcegroups/lis/workspaces/lis-ml&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 75d4dc12-810e-42ba-ad96-dd0efbf21791\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/75d4dc12-810e-42ba-ad96-dd0efbf21791?wsid=/subscriptions/2f091423-f84d-4062-8e67-1437a0c50045/resourcegroups/lis/workspaces/lis-ml&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "StepRun( Train ) Status: NotStarted\n",
      "StepRun( Train ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt\n",
      "========================================================================================================================\n",
      "2021-08-09T23:40:15Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/75d4dc12-810e-42ba-ad96-dd0efbf21791/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/75d4dc12-810e-42ba-ad96-dd0efbf21791/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=312240 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/75d4dc12-810e-42ba-ad96-dd0efbf21791/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      "2021-08-09T23:40:15Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/75d4dc12-810e-42ba-ad96-dd0efbf21791/mounts/workspaceblobstore\n",
      "2021-08-09T23:40:16Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/75d4dc12-810e-42ba-ad96-dd0efbf21791/mounts/lis_artifacts --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/75d4dc12-810e-42ba-ad96-dd0efbf21791/caches/lis_artifacts --file-cache-timeout-in-seconds=1000000 --cache-size-mb=312240 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/75d4dc12-810e-42ba-ad96-dd0efbf21791/configs/lis_artifacts.cfg --log-level=LOG_WARNING\n",
      "2021-08-09T23:40:16Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/75d4dc12-810e-42ba-ad96-dd0efbf21791/mounts/lis_artifacts\n",
      "2021-08-09T23:40:16Z Failed to start nvidia-fabricmanager due to exit status 5 with output Failed to start nvidia-fabricmanager.service: Unit nvidia-fabricmanager.service not found.\n",
      ". Please ignore this if the GPUs don't utilize NVIDIA® NVLink® switches.\n",
      "2021-08-09T23:40:16Z Starting output-watcher...\n",
      "2021-08-09T23:40:16Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-08-09T23:40:17Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2021-08-09T23:40:17Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_5572ea249a896c3014db8569f38d4a1a\n",
      "Digest: sha256:e4fcde8761b0dca23a91150bd7745746e90d05fb0e676a7adfc7e6fce5b6ce18\n",
      "Status: Image is up to date for viennaglobal.azurecr.io/azureml/azureml_5572ea249a896c3014db8569f38d4a1a:latest\n",
      "viennaglobal.azurecr.io/azureml/azureml_5572ea249a896c3014db8569f38d4a1a:latest\n",
      "2021-08-09T23:40:17Z Check if container 75d4dc12-810e-42ba-ad96-dd0efbf21791_DataSidecar already exist exited with 0, \n",
      "\n",
      "05d560d17fd03db9db78afcff2034090536a842f267cce94752e1209de82b8fe\n",
      "2021-08-09T23:40:18Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      "2021-08-09T23:40:18Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-8df8b6f5f5cfc01d5b61632947acb90d-bd38310d0fb34842-01 -sshRequired=false] \n",
      "2021/08/09 23:40:18 Starting App Insight Logger for task:  containerSetup\n",
      "2021/08/09 23:40:18 Version: 3.0.01676.0004 Branch: 2021-07-23 Commit: 2766ca7\n",
      "2021/08/09 23:40:18 Entered ContainerSetupTask - Preparing infiniband\n",
      "2021/08/09 23:40:18 Starting infiniband setup\n",
      "2021/08/09 23:40:18 Python Version found is Python 3.7.9\n",
      "\n",
      "2021/08/09 23:40:18 Returning Python Version as 3.7\n",
      "2021-08-09T23:40:18Z VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/08/09 23:40:18 VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/08/09 23:40:18 VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/08/09 23:40:18 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021-08-09T23:40:18Z Not setting up Infiniband in Container\n",
      "2021/08/09 23:40:18 Not setting up Infiniband in Container\n",
      "2021/08/09 23:40:18 Not setting up Infiniband in Container\n",
      "2021/08/09 23:40:18 Python Version found is Python 3.7.9\n",
      "\n",
      "2021/08/09 23:40:18 Returning Python Version as 3.7\n",
      "2021/08/09 23:40:18 sshd inside container not required for job, skipping setup.\n",
      "2021/08/09 23:40:18 All App Insights Logs was sent successfully or the close timeout of 20 was reached\n",
      "2021/08/09 23:40:18 App Insight Client has already been closed\n",
      "2021/08/09 23:40:18 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "2021-08-09T23:40:18Z Starting docker container succeeded.\n",
      "2021-08-09T23:40:32Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2021-08-09T23:40:32Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_3106eac23ddd7603fa7dab2694eb52ff\n",
      "Digest: sha256:64071389a06820223142eabd61e1b4bfd5e0b450131c8a50eef3c745fad8a73e\n",
      "Status: Image is up to date for 29bfa99a8943410c8e0210fa3a3417f5.azurecr.io/azureml/azureml_3106eac23ddd7603fa7dab2694eb52ff:latest\n",
      "29bfa99a8943410c8e0210fa3a3417f5.azurecr.io/azureml/azureml_3106eac23ddd7603fa7dab2694eb52ff:latest\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2021/08/09 23:40:33 Starting App Insight Logger for task:  runTaskLet\n",
      "2021/08/09 23:40:33 Version: 3.0.01676.0004 Branch: 2021-07-23 Commit: 2766ca7\n",
      "2021/08/09 23:40:33 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/info\n",
      "2021/08/09 23:40:33 Send process info logs to master server succeeded\n",
      "2021/08/09 23:40:33 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n",
      "2021/08/09 23:40:33 Send process info logs to master server succeeded\n",
      "[2021-08-09T23:40:33.926770] Entering context manager injector.\n",
      "[2021-08-09T23:40:34.416065] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['lis_components/train/train.py', '--model_name', 'gpt2', '--output_dir', 'DatasetOutputConfig:output_datastore_path', '--train_file', '/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/75d4dc12-810e-42ba-ad96-dd0efbf21791/mounts/lis_artifacts/data/train.csv', '--eval_file', '/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/75d4dc12-810e-42ba-ad96-dd0efbf21791/mounts/lis_artifacts/data/eval.csv', '--num_train_epochs', '10'])\n",
      "Script type = None\n",
      "[2021-08-09T23:40:34.419940] Entering Run History Context Manager.\n",
      "[2021-08-09T23:40:35.061284] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/75d4dc12-810e-42ba-ad96-dd0efbf21791/wd/azureml/75d4dc12-810e-42ba-ad96-dd0efbf21791\n",
      "[2021-08-09T23:40:35.061505] Preparing to call script [lis_components/train/train.py] with arguments:['--model_name', 'gpt2', '--output_dir', '$output_datastore_path', '--train_file', '/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/75d4dc12-810e-42ba-ad96-dd0efbf21791/mounts/lis_artifacts/data/train.csv', '--eval_file', '/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/75d4dc12-810e-42ba-ad96-dd0efbf21791/mounts/lis_artifacts/data/eval.csv', '--num_train_epochs', '10']\n",
      "[2021-08-09T23:40:35.061703] After variable expansion, calling script [lis_components/train/train.py] with arguments:['--model_name', 'gpt2', '--output_dir', '/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/75d4dc12-810e-42ba-ad96-dd0efbf21791/wd/output_datastore_path_lis_artifacts', '--train_file', '/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/75d4dc12-810e-42ba-ad96-dd0efbf21791/mounts/lis_artifacts/data/train.csv', '--eval_file', '/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/75d4dc12-810e-42ba-ad96-dd0efbf21791/mounts/lis_artifacts/data/eval.csv', '--num_train_epochs', '10']\n",
      "\n",
      "2021-08-09 23:40:35.220319: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_82f5617ca19cd57b18cafd61c017ea7a/lib:\n",
      "2021-08-09 23:40:35.220355: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Using custom data configuration default-c1f8635696f79b4d\n",
      "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-c1f8635696f79b4d/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff...\n",
      "\n",
      "0 tables [00:00, ? tables/s]\n",
      "                            \n",
      "\n",
      "0 tables [00:00, ? tables/s]\n",
      "                            \n",
      "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-c1f8635696f79b4d/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff. Subsequent calls will reuse this data.\n",
      "\n",
      "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]\n",
      "Downloading: 100%|██████████| 665/665 [00:00<00:00, 642kB/s]\n",
      "2021/08/09 23:40:38 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "\n",
      "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]\n",
      "Downloading:  17%|█▋        | 180k/1.04M [00:00<00:00, 1.11MB/s]\n",
      "Downloading:  86%|████████▋ | 901k/1.04M [00:00<00:00, 3.51MB/s]\n",
      "Downloading: 100%|██████████| 1.04M/1.04M [00:00<00:00, 3.19MB/s]\n",
      "\n",
      "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]\n",
      "Downloading:  39%|███▉      | 180k/456k [00:00<00:00, 1.13MB/s]\n",
      "Downloading: 100%|██████████| 456k/456k [00:00<00:00, 2.78MB/s]\n",
      "\n",
      "Adding eos_token to each example in the dataset:   0%|          | 0/11 [00:00<?, ?ba/s]\n",
      "Adding eos_token to each example in the dataset: 100%|██████████| 11/11 [00:00<00:00, 459.86ba/s]\n",
      "\n",
      "Adding eos_token to each example in the dataset:   0%|          | 0/4 [00:00<?, ?ba/s]\n",
      "Adding eos_token to each example in the dataset: 100%|██████████| 4/4 [00:00<00:00, 506.27ba/s]\n",
      "\n",
      "Running tokenizer on dataset:   0%|          | 0/11 [00:00<?, ?ba/s]\n",
      "Running tokenizer on dataset:   9%|▉         | 1/11 [00:00<00:01,  6.08ba/s]\n",
      "Running tokenizer on dataset:  18%|█▊        | 2/11 [00:00<00:01,  6.42ba/s]\n",
      "Running tokenizer on dataset:  27%|██▋       | 3/11 [00:00<00:01,  6.51ba/s]\n",
      "Running tokenizer on dataset:  36%|███▋      | 4/11 [00:00<00:01,  6.75ba/s]\n",
      "Running tokenizer on dataset:  45%|████▌     | 5/11 [00:00<00:00,  7.02ba/s]\n",
      "Running tokenizer on dataset:  55%|█████▍    | 6/11 [00:00<00:00,  6.89ba/s]\n",
      "Running tokenizer on dataset:  64%|██████▎   | 7/11 [00:01<00:00,  6.97ba/s]\n",
      "Running tokenizer on dataset:  73%|███████▎  | 8/11 [00:01<00:00,  6.97ba/s]\n",
      "Running tokenizer on dataset:  82%|████████▏ | 9/11 [00:01<00:00,  7.06ba/s]\n",
      "Running tokenizer on dataset:  91%|█████████ | 10/11 [00:01<00:00,  7.32ba/s]\n",
      "Running tokenizer on dataset: 100%|██████████| 11/11 [00:01<00:00,  7.66ba/s]\n",
      "\n",
      "Running tokenizer on dataset:   0%|          | 0/4 [00:00<?, ?ba/s]\n",
      "Running tokenizer on dataset:  25%|██▌       | 1/4 [00:00<00:00,  7.28ba/s]\n",
      "Running tokenizer on dataset:  50%|█████     | 2/4 [00:00<00:00,  7.49ba/s]\n",
      "Running tokenizer on dataset:  75%|███████▌  | 3/4 [00:00<00:00,  7.67ba/s]\n",
      "Running tokenizer on dataset: 100%|██████████| 4/4 [00:00<00:00,  9.88ba/s]\n",
      "\n",
      "Grouping texts in chunks of 1024:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "Grouping texts in chunks of 1024: 100%|██████████| 1/1 [00:06<00:00,  6.78s/ba]\n",
      "Grouping texts in chunks of 1024: 100%|██████████| 1/1 [00:06<00:00,  6.78s/ba]\n",
      "\n",
      "Grouping texts in chunks of 1024:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "Grouping texts in chunks of 1024: 100%|██████████| 1/1 [00:00<00:00,  1.64ba/s]\n",
      "Grouping texts in chunks of 1024: 100%|██████████| 1/1 [00:00<00:00,  1.64ba/s]\n",
      "2021-08-09 23:40:54.571713: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-09 23:40:54.606175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0cb7:00:00.0 name: Tesla K80 computeCapability: 3.7\n",
      "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
      "2021-08-09 23:40:54.606335: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_82f5617ca19cd57b18cafd61c017ea7a/lib:\n",
      "2021-08-09 23:40:54.606461: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_82f5617ca19cd57b18cafd61c017ea7a/lib:\n",
      "2021-08-09 23:40:54.606569: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_82f5617ca19cd57b18cafd61c017ea7a/lib:\n",
      "2021-08-09 23:40:54.606710: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_82f5617ca19cd57b18cafd61c017ea7a/lib:\n",
      "2021-08-09 23:40:54.606817: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_82f5617ca19cd57b18cafd61c017ea7a/lib:\n",
      "2021-08-09 23:40:54.606923: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_82f5617ca19cd57b18cafd61c017ea7a/lib:\n",
      "2021-08-09 23:40:54.607026: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_82f5617ca19cd57b18cafd61c017ea7a/lib:\n",
      "2021-08-09 23:40:54.607147: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_82f5617ca19cd57b18cafd61c017ea7a/lib:\n",
      "2021-08-09 23:40:54.607164: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-08-09 23:40:54.607652: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-09 23:40:54.608512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-09 23:40:54.608529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n",
      "\n",
      "Downloading:   0%|          | 0.00/498M [00:00<?, ?B/s]\n",
      "Downloading:   1%|          | 3.38M/498M [00:00<00:14, 33.8MB/s]\n",
      "Downloading:   2%|▏         | 10.2M/498M [00:00<00:09, 54.0MB/s]\n",
      "Downloading:   3%|▎         | 16.9M/498M [00:00<00:08, 59.9MB/s]\n",
      "Downloading:   5%|▍         | 23.6M/498M [00:00<00:07, 62.9MB/s]\n",
      "Downloading:   6%|▌         | 30.4M/498M [00:00<00:07, 64.7MB/s]\n",
      "Downloading:   7%|▋         | 37.3M/498M [00:00<00:06, 66.0MB/s]\n",
      "Downloading:   9%|▉         | 44.1M/498M [00:00<00:06, 66.8MB/s]\n",
      "Downloading:  10%|█         | 51.0M/498M [00:00<00:06, 67.3MB/s]\n",
      "Downloading:  12%|█▏        | 57.8M/498M [00:00<00:06, 67.6MB/s]\n",
      "Downloading:  13%|█▎        | 64.7M/498M [00:01<00:06, 68.0MB/s]\n",
      "Downloading:  14%|█▍        | 71.5M/498M [00:01<00:06, 68.1MB/s]\n",
      "Downloading:  16%|█▌        | 78.3M/498M [00:01<00:06, 68.1MB/s]\n",
      "Downloading:  17%|█▋        | 85.3M/498M [00:01<00:06, 68.7MB/s]\n",
      "Downloading:  19%|█▊        | 92.2M/498M [00:01<00:05, 68.6MB/s]\n",
      "Downloading:  20%|█▉        | 99.1M/498M [00:01<00:05, 68.7MB/s]\n",
      "Downloading:  21%|██▏       | 106M/498M [00:01<00:05, 68.8MB/s] \n",
      "Downloading:  23%|██▎       | 113M/498M [00:01<00:05, 66.7MB/s]\n",
      "Downloading:  24%|██▍       | 120M/498M [00:01<00:05, 66.5MB/s]\n",
      "Downloading:  25%|██▌       | 126M/498M [00:01<00:05, 66.4MB/s]\n",
      "Downloading:  27%|██▋       | 133M/498M [00:02<00:05, 66.2MB/s]\n",
      "Downloading:  28%|██▊       | 139M/498M [00:02<00:05, 66.3MB/s]\n",
      "Downloading:  29%|██▉       | 146M/498M [00:02<00:05, 66.2MB/s]\n",
      "Downloading:  31%|███       | 153M/498M [00:02<00:05, 66.4MB/s]\n",
      "Downloading:  32%|███▏      | 159M/498M [00:02<00:05, 65.9MB/s]\n",
      "Downloading:  33%|███▎      | 166M/498M [00:02<00:05, 65.8MB/s]\n",
      "Downloading:  35%|███▍      | 173M/498M [00:02<00:04, 65.5MB/s]\n",
      "Downloading:  36%|███▌      | 179M/498M [00:02<00:04, 64.9MB/s]\n",
      "Downloading:  37%|███▋      | 186M/498M [00:02<00:04, 64.9MB/s]\n",
      "Downloading:  39%|███▊      | 192M/498M [00:02<00:04, 64.7MB/s]\n",
      "Downloading:  40%|███▉      | 199M/498M [00:03<00:04, 64.7MB/s]\n",
      "Downloading:  41%|████      | 205M/498M [00:03<00:04, 65.1MB/s]\n",
      "Downloading:  43%|████▎     | 212M/498M [00:03<00:04, 65.5MB/s]\n",
      "Downloading:  44%|████▍     | 218M/498M [00:03<00:04, 65.4MB/s]\n",
      "Downloading:  45%|████▌     | 225M/498M [00:03<00:04, 65.1MB/s]\n",
      "Downloading:  46%|████▋     | 232M/498M [00:03<00:04, 65.2MB/s]\n",
      "Downloading:  48%|████▊     | 238M/498M [00:03<00:03, 65.4MB/s]\n",
      "Downloading:  49%|████▉     | 245M/498M [00:03<00:03, 65.8MB/s]\n",
      "Downloading:  50%|█████     | 251M/498M [00:03<00:03, 65.9MB/s]\n",
      "Downloading:  52%|█████▏    | 258M/498M [00:03<00:03, 65.1MB/s]\n",
      "Downloading:  53%|█████▎    | 265M/498M [00:04<00:03, 65.3MB/s]\n",
      "Downloading:  54%|█████▍    | 271M/498M [00:04<00:03, 65.7MB/s]\n",
      "Downloading:  56%|█████▌    | 278M/498M [00:04<00:03, 65.8MB/s]\n",
      "Downloading:  57%|█████▋    | 284M/498M [00:04<00:03, 65.5MB/s]\n",
      "Downloading:  58%|█████▊    | 291M/498M [00:04<00:03, 65.8MB/s]\n",
      "Downloading:  60%|█████▉    | 298M/498M [00:04<00:03, 65.8MB/s]\n",
      "Downloading:  61%|██████    | 304M/498M [00:04<00:02, 65.8MB/s]\n",
      "Downloading:  62%|██████▏   | 311M/498M [00:04<00:02, 66.3MB/s]\n",
      "Downloading:  64%|██████▍   | 318M/498M [00:04<00:02, 66.3MB/s]\n",
      "Downloading:  65%|██████▌   | 324M/498M [00:04<00:02, 66.9MB/s]\n",
      "Downloading:  67%|██████▋   | 331M/498M [00:05<00:02, 67.0MB/s]\n",
      "Downloading:  68%|██████▊   | 338M/498M [00:05<00:02, 66.9MB/s]\n",
      "Downloading:  69%|██████▉   | 345M/498M [00:05<00:02, 66.9MB/s]\n",
      "Downloading:  71%|███████   | 351M/498M [00:05<00:02, 65.3MB/s]\n",
      "Downloading:  72%|███████▏  | 358M/498M [00:05<00:02, 65.8MB/s]\n",
      "Downloading:  73%|███████▎  | 365M/498M [00:05<00:02, 66.0MB/s]\n",
      "Downloading:  75%|███████▍  | 371M/498M [00:05<00:01, 66.4MB/s]\n",
      "Downloading:  76%|███████▌  | 378M/498M [00:05<00:01, 66.5MB/s]\n",
      "Downloading:  77%|███████▋  | 385M/498M [00:05<00:01, 66.5MB/s]\n",
      "Downloading:  79%|███████▊  | 391M/498M [00:05<00:01, 66.4MB/s]\n",
      "Downloading:  80%|███████▉  | 398M/498M [00:06<00:01, 66.4MB/s]\n",
      "Downloading:  81%|████████▏ | 405M/498M [00:06<00:01, 64.7MB/s]\n",
      "Downloading:  83%|████████▎ | 411M/498M [00:06<00:01, 65.4MB/s]\n",
      "Downloading:  84%|████████▍ | 418M/498M [00:06<00:01, 64.8MB/s]\n",
      "Downloading:  85%|████████▌ | 425M/498M [00:06<00:01, 65.2MB/s]\n",
      "Downloading:  87%|████████▋ | 431M/498M [00:06<00:01, 65.3MB/s]\n",
      "Downloading:  88%|████████▊ | 438M/498M [00:06<00:00, 64.9MB/s]\n",
      "Downloading:  89%|████████▉ | 444M/498M [00:06<00:00, 64.6MB/s]\n",
      "Downloading:  91%|█████████ | 451M/498M [00:06<00:00, 65.2MB/s]\n",
      "Downloading:  92%|█████████▏| 457M/498M [00:06<00:00, 65.6MB/s]\n",
      "Downloading:  93%|█████████▎| 464M/498M [00:07<00:00, 65.1MB/s]\n",
      "Downloading:  94%|█████████▍| 470M/498M [00:07<00:00, 65.2MB/s]\n",
      "Downloading:  96%|█████████▌| 477M/498M [00:07<00:00, 65.5MB/s]\n",
      "Downloading:  97%|█████████▋| 484M/498M [00:07<00:00, 65.6MB/s]\n",
      "Downloading:  98%|█████████▊| 490M/498M [00:07<00:00, 65.3MB/s]\n",
      "Downloading: 100%|█████████▉| 497M/498M [00:07<00:00, 62.7MB/s]\n",
      "Downloading: 100%|██████████| 498M/498M [00:07<00:00, 65.6MB/s]\n",
      "2021-08-09 23:41:03.208039: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "2021-08-09 23:41:05.188580: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-08-09 23:41:05.189010: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2596985000 Hz\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From /azureml-envs/azureml_82f5617ca19cd57b18cafd61c017ea7a/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "\n",
      " 1/18 [>.............................] - ETA: 14:09 - loss: 3.5744 - output_1_loss: 3.5744\n",
      " 2/18 [==>...........................] - ETA: 8:40 - loss: 3.2333 - output_1_loss: 3.2333 \n",
      " 3/18 [====>.........................] - ETA: 8:07 - loss: 3.0563 - output_1_loss: 3.0563\n",
      " 4/18 [=====>........................] - ETA: 7:34 - loss: 2.9711 - output_1_loss: 2.9711\n",
      " 5/18 [=======>......................] - ETA: 7:01 - loss: 2.8854 - output_1_loss: 2.8854\n",
      " 6/18 [=========>....................] - ETA: 6:29 - loss: 2.8020 - output_1_loss: 2.8020\n",
      " 7/18 [==========>...................] - ETA: 5:56 - loss: 2.7384 - output_1_loss: 2.7384\n",
      " 8/18 [============>.................] - ETA: 5:24 - loss: 2.6703 - output_1_loss: 2.6703\n",
      " 9/18 [==============>...............] - ETA: 4:52 - loss: 2.6415 - output_1_loss: 2.6415\n",
      "10/18 [===============>..............] - ETA: 4:19 - loss: 2.6254 - output_1_loss: 2.6254\n",
      "11/18 [=================>............] - ETA: 3:47 - loss: 2.5975 - output_1_loss: 2.5975\n",
      "12/18 [===================>..........] - ETA: 3:14 - loss: 2.5716 - output_1_loss: 2.5716\n",
      "13/18 [====================>.........] - ETA: 2:42 - loss: 2.5469 - output_1_loss: 2.5469\n",
      "14/18 [======================>.......] - ETA: 2:09 - loss: 2.5336 - output_1_loss: 2.5336\n",
      "15/18 [========================>.....] - ETA: 1:37 - loss: 2.5122 - output_1_loss: 2.5122\n",
      "16/18 [=========================>....] - ETA: 1:04 - loss: 2.4963 - output_1_loss: 2.4963\n",
      "17/18 [===========================>..] - ETA: 32s - loss: 2.4840 - output_1_loss: 2.4840 \n",
      "18/18 [==============================] - ETA: 0s - loss: 2.4677 - output_1_loss: 2.4677 \n",
      "18/18 [==============================] - 1129s 64s/step - loss: 2.4677 - output_1_loss: 2.4677 - val_loss: 2.1845 - val_output_1_loss: 2.1845\n",
      "Epoch 2/10\n",
      "\n",
      " 1/18 [>.............................] - ETA: 9:17 - loss: 2.2078 - output_1_loss: 2.2078\n",
      " 2/18 [==>...........................] - ETA: 8:37 - loss: 2.1537 - output_1_loss: 2.1537\n",
      " 3/18 [====>.........................] - ETA: 8:04 - loss: 2.1609 - output_1_loss: 2.1609\n",
      " 4/18 [=====>........................] - ETA: 7:32 - loss: 2.1874 - output_1_loss: 2.1874\n",
      " 5/18 [=======>......................] - ETA: 7:01 - loss: 2.1864 - output_1_loss: 2.1864\n",
      "\n",
      " 1/18 [>.............................] - ETA: 9:11 - loss: 2.1710 - output_1_loss: 2.1710\n",
      " 2/18 [==>...........................] - ETA: 8:41 - loss: 2.1236 - output_1_loss: 2.1236\n",
      " 3/18 [====>.........................] - ETA: 8:08 - loss: 2.0793 - output_1_loss: 2.0793\n",
      " 4/18 [=====>........................] - ETA: 7:35 - loss: 2.0779 - output_1_loss: 2.0779\n",
      " 5/18 [=======>......................] - ETA: 7:02 - loss: 2.0806 - output_1_loss: 2.0806\n",
      " 6/18 [=========>....................] - ETA: 6:30 - loss: 2.0623 - output_1_loss: 2.0623\n",
      " 7/18 [==========>...................] - ETA: 5:57 - loss: 2.0762 - output_1_loss: 2.0762\n",
      " 8/18 [============>.................] - ETA: 5:25 - loss: 2.0800 - output_1_loss: 2.0800\n",
      " 9/18 [==============>...............] - ETA: 4:52 - loss: 2.0904 - output_1_loss: 2.0904\n",
      "10/18 [===============>..............] - ETA: 4:20 - loss: 2.0869 - output_1_loss: 2.0869\n",
      "11/18 [=================>............] - ETA: 3:47 - loss: 2.0946 - output_1_loss: 2.0946\n",
      "12/18 [===================>..........] - ETA: 3:15 - loss: 2.0883 - output_1_loss: 2.0883\n",
      "13/18 [====================>.........] - ETA: 2:42 - loss: 2.0875 - output_1_loss: 2.0875\n",
      "14/18 [======================>.......] - ETA: 2:10 - loss: 2.0830 - output_1_loss: 2.0830\n",
      "15/18 [========================>.....] - ETA: 1:37 - loss: 2.0769 - output_1_loss: 2.0769\n",
      "16/18 [=========================>....] - ETA: 1:05 - loss: 2.0723 - output_1_loss: 2.0723\n",
      "17/18 [===========================>..] - ETA: 32s - loss: 2.0670 - output_1_loss: 2.0670 \n",
      "18/18 [==============================] - ETA: 0s - loss: 2.0637 - output_1_loss: 2.0637 \n",
      "18/18 [==============================] - 1111s 63s/step - loss: 2.0637 - output_1_loss: 2.0637 - val_loss: 2.0366 - val_output_1_loss: 2.0366\n",
      "Epoch 4/10\n",
      "\n",
      " 1/18 [>.............................] - ETA: 9:12 - loss: 1.9088 - output_1_loss: 1.9088\n",
      " 2/18 [==>...........................] - ETA: 8:38 - loss: 1.9598 - output_1_loss: 1.9598\n",
      " 3/18 [====>.........................] - ETA: 8:07 - loss: 1.9682 - output_1_loss: 1.9682\n",
      " 4/18 [=====>........................] - ETA: 7:34 - loss: 1.9737 - output_1_loss: 1.9737\n",
      " 5/18 [=======>......................] - ETA: 7:02 - loss: 1.9806 - output_1_loss: 1.9806\n",
      " 6/18 [=========>....................] - ETA: 6:29 - loss: 2.0038 - output_1_loss: 2.0038\n",
      " 7/18 [==========>...................] - ETA: 5:57 - loss: 1.9895 - output_1_loss: 1.9895\n",
      " 8/18 [============>.................] - ETA: 5:24 - loss: 1.9976 - output_1_loss: 1.9976\n",
      " 9/18 [==============>...............] - ETA: 4:52 - loss: 2.0099 - output_1_loss: 2.0099\n",
      "10/18 [===============>..............] - ETA: 4:19 - loss: 2.0156 - output_1_loss: 2.0156\n",
      "11/18 [=================>............] - ETA: 3:47 - loss: 2.0129 - output_1_loss: 2.0129\n",
      "12/18 [===================>..........] - ETA: 3:14 - loss: 2.0121 - output_1_loss: 2.0121\n",
      "13/18 [====================>.........] - ETA: 2:42 - loss: 2.0120 - output_1_loss: 2.0120\n",
      "14/18 [======================>.......] - ETA: 2:09 - loss: 2.0104 - output_1_loss: 2.0104\n",
      "15/18 [========================>.....] - ETA: 1:37 - loss: 2.0094 - output_1_loss: 2.0094\n",
      "16/18 [=========================>....] - ETA: 1:04 - loss: 2.0125 - output_1_loss: 2.0125\n",
      "17/18 [===========================>..] - ETA: 32s - loss: 2.0161 - output_1_loss: 2.0161 \n",
      "18/18 [==============================] - ETA: 0s - loss: 2.0127 - output_1_loss: 2.0127 \n",
      "18/18 [==============================] - 1109s 63s/step - loss: 2.0127 - output_1_loss: 2.0127 - val_loss: 2.0110 - val_output_1_loss: 2.0110\n",
      "Epoch 5/10\n",
      "\n",
      " 1/18 [>.............................] - ETA: 9:11 - loss: 2.0359 - output_1_loss: 2.0359\n",
      " 2/18 [==>...........................] - ETA: 8:38 - loss: 1.9453 - output_1_loss: 1.9453\n",
      " 3/18 [====>.........................] - ETA: 8:06 - loss: 1.9593 - output_1_loss: 1.9593\n",
      " 4/18 [=====>........................] - ETA: 7:34 - loss: 2.0041 - output_1_loss: 2.0041\n",
      " 5/18 [=======>......................] - ETA: 7:02 - loss: 2.0025 - output_1_loss: 2.0025\n",
      " 6/18 [=========>....................] - ETA: 6:29 - loss: 2.0134 - output_1_loss: 2.0134\n",
      " 7/18 [==========>...................] - ETA: 5:57 - loss: 2.0080 - output_1_loss: 2.0080\n",
      " 8/18 [============>.................] - ETA: 5:24 - loss: 2.0049 - output_1_loss: 2.0049\n",
      " 9/18 [==============>...............] - ETA: 4:52 - loss: 1.9949 - output_1_loss: 1.9949\n",
      "10/18 [===============>..............] - ETA: 4:19 - loss: 1.9911 - output_1_loss: 1.9911\n",
      "11/18 [=================>............] - ETA: 3:47 - loss: 1.9865 - output_1_loss: 1.9865\n",
      "12/18 [===================>..........] - ETA: 3:14 - loss: 1.9964 - output_1_loss: 1.9964\n",
      "13/18 [====================>.........] - ETA: 2:42 - loss: 2.0017 - output_1_loss: 2.0017\n",
      "14/18 [======================>.......] - ETA: 2:09 - loss: 1.9981 - output_1_loss: 1.9981\n",
      "15/18 [========================>.....] - ETA: 1:37 - loss: 1.9885 - output_1_loss: 1.9885\n",
      "16/18 [=========================>....] - ETA: 1:04 - loss: 1.9843 - output_1_loss: 1.9843\n",
      "17/18 [===========================>..] - ETA: 32s - loss: 1.9800 - output_1_loss: 1.9800 \n",
      "18/18 [==============================] - ETA: 0s - loss: 1.9712 - output_1_loss: 1.9712 \n",
      "18/18 [==============================] - 1110s 63s/step - loss: 1.9712 - output_1_loss: 1.9712 - val_loss: 1.9910 - val_output_1_loss: 1.9910\n",
      "Epoch 6/10\n",
      "\n",
      " 1/18 [>.............................] - ETA: 9:14 - loss: 1.8666 - output_1_loss: 1.8666\n",
      " 2/18 [==>...........................] - ETA: 8:37 - loss: 1.8877 - output_1_loss: 1.8877\n",
      " 3/18 [====>.........................] - ETA: 8:05 - loss: 1.8926 - output_1_loss: 1.8926\n",
      " 4/18 [=====>........................] - ETA: 7:33 - loss: 1.9218 - output_1_loss: 1.9218\n",
      " 5/18 [=======>......................] - ETA: 7:01 - loss: 1.9381 - output_1_loss: 1.9381\n",
      " 6/18 [=========>....................] - ETA: 6:28 - loss: 1.9468 - output_1_loss: 1.9468\n",
      " 7/18 [==========>...................] - ETA: 5:56 - loss: 1.9376 - output_1_loss: 1.9376\n",
      " 8/18 [============>.................] - ETA: 5:24 - loss: 1.9297 - output_1_loss: 1.9297\n",
      " 9/18 [==============>...............] - ETA: 4:51 - loss: 1.9357 - output_1_loss: 1.9357\n",
      "10/18 [===============>..............] - ETA: 4:19 - loss: 1.9203 - output_1_loss: 1.9203\n",
      "11/18 [=================>............] - ETA: 3:47 - loss: 1.9234 - output_1_loss: 1.9234\n",
      "12/18 [===================>..........] - ETA: 3:14 - loss: 1.9324 - output_1_loss: 1.9324\n",
      "13/18 [====================>.........] - ETA: 2:42 - loss: 1.9256 - output_1_loss: 1.9256\n",
      "14/18 [======================>.......] - ETA: 2:09 - loss: 1.9361 - output_1_loss: 1.9361\n",
      "15/18 [========================>.....] - ETA: 1:37 - loss: 1.9355 - output_1_loss: 1.9355\n",
      "16/18 [=========================>....] - ETA: 1:04 - loss: 1.9408 - output_1_loss: 1.9408\n",
      "17/18 [===========================>..] - ETA: 32s - loss: 1.9437 - output_1_loss: 1.9437 \n",
      "18/18 [==============================] - ETA: 0s - loss: 1.9418 - output_1_loss: 1.9418 \n",
      "18/18 [==============================] - 1113s 64s/step - loss: 1.9418 - output_1_loss: 1.9418 - val_loss: 1.9754 - val_output_1_loss: 1.9754\n",
      "Epoch 7/10\n",
      "\n",
      " 1/18 [>.............................] - ETA: 9:16 - loss: 1.9219 - output_1_loss: 1.9219\n",
      " 2/18 [==>...........................] - ETA: 8:39 - loss: 1.9292 - output_1_loss: 1.9292\n",
      " 3/18 [====>.........................] - ETA: 8:09 - loss: 1.9056 - output_1_loss: 1.9056\n",
      " 4/18 [=====>........................] - ETA: 7:36 - loss: 1.9248 - output_1_loss: 1.9248\n",
      " 5/18 [=======>......................] - ETA: 7:03 - loss: 1.8987 - output_1_loss: 1.8987\n",
      " 6/18 [=========>....................] - ETA: 6:30 - loss: 1.9021 - output_1_loss: 1.9021\n",
      " 7/18 [==========>...................] - ETA: 5:58 - loss: 1.9197 - output_1_loss: 1.9197\n",
      " 8/18 [============>.................] - ETA: 5:25 - loss: 1.9047 - output_1_loss: 1.9047\n",
      " 9/18 [==============>...............] - ETA: 4:53 - loss: 1.9077 - output_1_loss: 1.9077\n",
      "10/18 [===============>..............] - ETA: 4:20 - loss: 1.9059 - output_1_loss: 1.9059\n",
      "11/18 [=================>............] - ETA: 3:48 - loss: 1.9022 - output_1_loss: 1.9022\n",
      "12/18 [===================>..........] - ETA: 3:15 - loss: 1.9017 - output_1_loss: 1.9017\n",
      "13/18 [====================>.........] - ETA: 2:42 - loss: 1.9008 - output_1_loss: 1.9008\n",
      "14/18 [======================>.......] - ETA: 2:10 - loss: 1.9119 - output_1_loss: 1.9119\n",
      "15/18 [========================>.....] - ETA: 1:37 - loss: 1.9147 - output_1_loss: 1.9147\n",
      "16/18 [=========================>....] - ETA: 1:05 - loss: 1.9176 - output_1_loss: 1.9176\n",
      "17/18 [===========================>..] - ETA: 32s - loss: 1.9191 - output_1_loss: 1.9191 \n",
      "18/18 [==============================] - ETA: 0s - loss: 1.9195 - output_1_loss: 1.9195 \n",
      "18/18 [==============================] - 1111s 63s/step - loss: 1.9195 - output_1_loss: 1.9195 - val_loss: 1.9666 - val_output_1_loss: 1.9666\n",
      "Epoch 8/10\n",
      "\n",
      " 1/18 [>.............................] - ETA: 9:16 - loss: 1.9820 - output_1_loss: 1.9820\n",
      " 2/18 [==>...........................] - ETA: 8:41 - loss: 1.9151 - output_1_loss: 1.9151\n",
      " 3/18 [====>.........................] - ETA: 8:07 - loss: 1.9395 - output_1_loss: 1.9395\n",
      " 4/18 [=====>........................] - ETA: 7:35 - loss: 1.9267 - output_1_loss: 1.9267\n",
      " 5/18 [=======>......................] - ETA: 7:03 - loss: 1.9381 - output_1_loss: 1.9381\n",
      " 6/18 [=========>....................] - ETA: 6:31 - loss: 1.9189 - output_1_loss: 1.9189\n",
      " 7/18 [==========>...................] - ETA: 5:58 - loss: 1.9082 - output_1_loss: 1.9082\n",
      " 8/18 [============>.................] - ETA: 5:26 - loss: 1.8941 - output_1_loss: 1.8941\n",
      " 9/18 [==============>...............] - ETA: 4:53 - loss: 1.8932 - output_1_loss: 1.8932\n",
      "10/18 [===============>..............] - ETA: 4:20 - loss: 1.8875 - output_1_loss: 1.8875\n",
      "11/18 [=================>............] - ETA: 3:47 - loss: 1.8987 - output_1_loss: 1.8987\n",
      "12/18 [===================>..........] - ETA: 3:15 - loss: 1.9038 - output_1_loss: 1.9038\n",
      "13/18 [====================>.........] - ETA: 2:42 - loss: 1.9066 - output_1_loss: 1.9066\n",
      "14/18 [======================>.......] - ETA: 2:10 - loss: 1.9031 - output_1_loss: 1.9031\n",
      "15/18 [========================>.....] - ETA: 1:37 - loss: 1.9083 - output_1_loss: 1.9083\n",
      "16/18 [=========================>....] - ETA: 1:05 - loss: 1.9089 - output_1_loss: 1.9089\n",
      "17/18 [===========================>..] - ETA: 32s - loss: 1.9065 - output_1_loss: 1.9065 \n",
      "18/18 [==============================] - ETA: 0s - loss: 1.9037 - output_1_loss: 1.9037 \n",
      "18/18 [==============================] - 1112s 64s/step - loss: 1.9037 - output_1_loss: 1.9037 - val_loss: 1.9574 - val_output_1_loss: 1.9574\n",
      "Epoch 9/10\n",
      "\n",
      " 1/18 [>.............................] - ETA: 9:10 - loss: 1.8725 - output_1_loss: 1.8725\n",
      " 2/18 [==>...........................] - ETA: 8:39 - loss: 1.8353 - output_1_loss: 1.8353\n",
      " 3/18 [====>.........................] - ETA: 8:07 - loss: 1.8573 - output_1_loss: 1.8573\n",
      " 4/18 [=====>........................] - ETA: 7:34 - loss: 1.8759 - output_1_loss: 1.8759\n",
      " 5/18 [=======>......................] - ETA: 7:02 - loss: 1.8776 - output_1_loss: 1.8776\n",
      " 6/18 [=========>....................] - ETA: 6:29 - loss: 1.8830 - output_1_loss: 1.8830\n",
      " 7/18 [==========>...................] - ETA: 5:56 - loss: 1.8811 - output_1_loss: 1.8811\n",
      " 8/18 [============>.................] - ETA: 5:24 - loss: 1.8763 - output_1_loss: 1.8763\n",
      " 9/18 [==============>...............] - ETA: 4:51 - loss: 1.8856 - output_1_loss: 1.8856\n",
      "10/18 [===============>..............] - ETA: 4:19 - loss: 1.8942 - output_1_loss: 1.8942\n",
      "11/18 [=================>............] - ETA: 3:46 - loss: 1.8931 - output_1_loss: 1.8931\n",
      "12/18 [===================>..........] - ETA: 3:14 - loss: 1.8971 - output_1_loss: 1.8971\n",
      "13/18 [====================>.........] - ETA: 2:42 - loss: 1.8955 - output_1_loss: 1.8955\n",
      "14/18 [======================>.......] - ETA: 2:09 - loss: 1.8989 - output_1_loss: 1.8989\n",
      "15/18 [========================>.....] - ETA: 1:37 - loss: 1.8966 - output_1_loss: 1.8966\n",
      "16/18 [=========================>....] - ETA: 1:04 - loss: 1.8962 - output_1_loss: 1.8962\n",
      "17/18 [===========================>..] - ETA: 32s - loss: 1.8954 - output_1_loss: 1.8954 \n",
      "18/18 [==============================] - ETA: 0s - loss: 1.8922 - output_1_loss: 1.8922 \n",
      "18/18 [==============================] - 1110s 63s/step - loss: 1.8922 - output_1_loss: 1.8922 - val_loss: 1.9555 - val_output_1_loss: 1.9555\n",
      "Epoch 10/10\n",
      "\n",
      " 1/18 [>.............................] - ETA: 9:13 - loss: 1.8122 - output_1_loss: 1.8122\n",
      " 2/18 [==>...........................] - ETA: 8:41 - loss: 1.8344 - output_1_loss: 1.8344\n",
      " 3/18 [====>.........................] - ETA: 8:08 - loss: 1.8327 - output_1_loss: 1.8327\n",
      " 4/18 [=====>........................] - ETA: 7:35 - loss: 1.8695 - output_1_loss: 1.8695\n",
      " 5/18 [=======>......................] - ETA: 7:03 - loss: 1.8976 - output_1_loss: 1.8976\n",
      " 6/18 [=========>....................] - ETA: 6:31 - loss: 1.8872 - output_1_loss: 1.8872\n",
      " 7/18 [==========>...................] - ETA: 5:58 - loss: 1.8979 - output_1_loss: 1.8979\n",
      " 8/18 [============>.................] - ETA: 5:26 - loss: 1.9163 - output_1_loss: 1.9163\n",
      " 9/18 [==============>...............] - ETA: 4:53 - loss: 1.9049 - output_1_loss: 1.9049\n",
      "10/18 [===============>..............] - ETA: 4:21 - loss: 1.8991 - output_1_loss: 1.8991\n",
      "11/18 [=================>............] - ETA: 3:48 - loss: 1.8886 - output_1_loss: 1.8886\n",
      "12/18 [===================>..........] - ETA: 3:15 - loss: 1.8892 - output_1_loss: 1.8892\n",
      "13/18 [====================>.........] - ETA: 2:43 - loss: 1.8913 - output_1_loss: 1.8913\n",
      "14/18 [======================>.......] - ETA: 2:10 - loss: 1.8848 - output_1_loss: 1.8848\n",
      "15/18 [========================>.....] - ETA: 1:37 - loss: 1.8879 - output_1_loss: 1.8879\n",
      "16/18 [=========================>....] - ETA: 1:05 - loss: 1.8847 - output_1_loss: 1.8847\n",
      "17/18 [===========================>..] - ETA: 32s - loss: 1.8834 - output_1_loss: 1.8834 \n",
      "18/18 [==============================] - ETA: 0s - loss: 1.8863 - output_1_loss: 1.8863 \n",
      "18/18 [==============================] - 1115s 64s/step - loss: 1.8863 - output_1_loss: 1.8863 - val_loss: 1.9543 - val_output_1_loss: 1.9543\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt\n",
      "===============================================================================================================\n",
      "[2021-08-10T02:51:16.098827] Entering job release\n",
      "[2021-08-10T02:51:16.895204] Starting job release\n",
      "[2021-08-10T02:51:16.895609] Logging experiment finalizing status in history service.\n",
      "[2021-08-10T02:51:16.895785] job release stage : upload_datastore starting...Starting the daemon thread to refresh tokens in background for process with pid = 3138\n",
      "\n",
      "[2021-08-10T02:51:16.896145] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-08-10T02:51:16.896787] job release stage : execute_job_release starting...[2021-08-10T02:51:16.896926] job release stage : copy_batchai_cached_logs starting...\n",
      "\n",
      "[2021-08-10T02:51:16.899124] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-08-10T02:51:16.910443] Entering context manager injector.\n",
      "[2021-08-10T02:51:16.933051] job release stage : upload_datastore completed...\n",
      "[2021-08-10T02:51:17.035977] job release stage : send_run_telemetry starting...\n",
      "[2021-08-10T02:51:17.044714] get vm size and vm region successfully.\n",
      "[2021-08-10T02:51:17.051511] get compute meta data successfully.\n",
      "[2021-08-10T02:51:17.124698] job release stage : execute_job_release completed...\n",
      "[2021-08-10T02:51:17.312050] post artifact meta request successfully.\n",
      "[2021-08-10T02:51:17.351811] upload compute record artifact successfully.\n",
      "[2021-08-10T02:51:17.351882] job release stage : send_run_telemetry completed...\n",
      "[2021-08-10T02:51:17.352265] Running in AzureML-Sidecar, starting to exit user context managers...\n",
      "[2021-08-10T02:51:17.352361] Running Sidecar release cmd...\n",
      "[2021-08-10T02:51:17.363102] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/75d4dc12-810e-42ba-ad96-dd0efbf21791/wd/azureml/75d4dc12-810e-42ba-ad96-dd0efbf21791\n",
      "Enter __exit__ of DatasetContextManager\n",
      "Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/75d4dc12-810e-42ba-ad96-dd0efbf21791/wd/output_datastore_path_lis_artifacts.\n",
      "Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/75d4dc12-810e-42ba-ad96-dd0efbf21791/wd/output_datastore_path_lis_artifacts.\n",
      "Exit __exit__ of DatasetContextManager\n",
      "[2021-08-10T02:51:17.480084] Removing absolute paths from host...\n",
      "[2021-08-10T02:51:17.480285] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
      "[2021-08-10T02:51:17.770610] Ran Sidecar release cmd.\n",
      "[2021-08-10T02:51:17.770700] Job release is complete\n",
      "\n",
      "StepRun(Train) Execution Summary\n",
      "=================================\n",
      "StepRun( Train ) Status: Finished\n",
      "{'runId': '75d4dc12-810e-42ba-ad96-dd0efbf21791', 'target': 'pipeline-cluster', 'status': 'Completed', 'startTimeUtc': '2021-08-09T23:40:17.822646Z', 'endTimeUtc': '2021-08-10T02:51:25.679492Z', 'properties': {'ContentSnapshotId': 'f9ae6227-5f97-4b26-87c7-304c3402c618', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '9f0b75a2-76b6-47e6-a8d3-19f505f6f2c5', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '9373786c', 'azureml.pipelinerunid': 'c61e6022-be86-4993-aaac-02f08f2d3152', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'azureml.RuntimeType': 'Hosttools'}, 'inputDatasets': [], 'outputDatasets': [{'identifier': {'savedId': '6c598996-ab02-4468-ad73-9acfbe6572cf'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'output_datastore_path'}, 'dataset': {\n",
      "  \"source\": [\n",
      "    \"('lis_artifacts', 'outputs')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"6c598996-ab02-4468-ad73-9acfbe6572cf\",\n",
      "    \"name\": null,\n",
      "    \"version\": null,\n",
      "    \"workspace\": \"Workspace.create(name='lis-ml', subscription_id='2f091423-f84d-4062-8e67-1437a0c50045', resource_group='lis')\"\n",
      "  }\n",
      "}}], 'runDefinition': {'script': 'lis_components/train/train.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--model_name', 'gpt2', '--output_dir', 'DatasetOutputConfig:output_datastore_path', '--train_file', '$AZUREML_DATAREFERENCE_train_datastore_path', '--eval_file', '$AZUREML_DATAREFERENCE_eval_datastore_path', '--num_train_epochs', '$AML_PARAMETER_num_train_epochs'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'pipeline-cluster', 'dataReferences': {'train_datastore_path': {'dataStoreName': 'lis_artifacts', 'mode': 'Mount', 'pathOnDataStore': 'data/train.csv', 'pathOnCompute': None, 'overwrite': False}, 'eval_datastore_path': {'dataStoreName': 'lis_artifacts', 'mode': 'Mount', 'pathOnDataStore': 'data/eval.csv', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'outputData': {'output_datastore_path': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'lis_artifacts', 'relativePath': 'outputs'}, 'uri': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': None, 'description': None, 'tags': None, 'datasetRegistrationOptions': {'additionalTransformation': None}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'pipeline-env', 'version': 'Autosave_2021-08-09T13:40:51Z_738b2e1a', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'dependencies': ['python=3.6.9', 'pip', {'pip': ['transformers == 3.5.1', 'datasets == 1.10.2', 'tensorflow == 2.5.0', 'azureml-defaults==1.30.0']}], 'name': 'azureml_82f5617ca19cd57b18cafd61c017ea7a'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210531.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'AISupercomputer.D2', 'imageVersion': 'pytorch-1.7.0', 'location': 'westus2', 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard'}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {'AML_PARAMETER_num_train_epochs': '10'}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.75d4dc12-810e-42ba-ad96-dd0efbf21791/azureml-logs/55_azureml-execution-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt?sv=2019-07-07&sr=b&sig=qRoqsO9J%2BD3nn%2BCsEpW5BBRLcbNO3KdzJiDTzIM6BZo%3D&st=2021-08-10T02%3A41%3A17Z&se=2021-08-10T10%3A51%3A17Z&sp=r', 'azureml-logs/65_job_prep-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.75d4dc12-810e-42ba-ad96-dd0efbf21791/azureml-logs/65_job_prep-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt?sv=2019-07-07&sr=b&sig=A2JM1n%2BGdWAcDAL4EoLws1KoBEwab6xKBazjDCLTpwg%3D&st=2021-08-10T02%3A41%3A17Z&se=2021-08-10T10%3A51%3A17Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.75d4dc12-810e-42ba-ad96-dd0efbf21791/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=tNPuxdXwV1%2F0McoWiB6oglJW0Rb%2Bqx60JbwIvRxr1Lc%3D&st=2021-08-10T02%3A41%3A17Z&se=2021-08-10T10%3A51%3A17Z&sp=r', 'azureml-logs/75_job_post-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.75d4dc12-810e-42ba-ad96-dd0efbf21791/azureml-logs/75_job_post-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt?sv=2019-07-07&sr=b&sig=0c2mjGcOGc9gJmXt6GJmcUs4VMgvxIWLYdBzLkt8i5A%3D&st=2021-08-10T02%3A41%3A17Z&se=2021-08-10T10%3A51%3A17Z&sp=r', 'azureml-logs/process_info.json': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.75d4dc12-810e-42ba-ad96-dd0efbf21791/azureml-logs/process_info.json?sv=2019-07-07&sr=b&sig=1%2Fxy99DppEQ6R4x1VsvWpEtIWSKAKk9hMt7ctoumskg%3D&st=2021-08-10T02%3A41%3A17Z&se=2021-08-10T10%3A51%3A17Z&sp=r', 'azureml-logs/process_status.json': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.75d4dc12-810e-42ba-ad96-dd0efbf21791/azureml-logs/process_status.json?sv=2019-07-07&sr=b&sig=NIL4NqZLPbjDimCu9MaCrW6E1IhbvEX7oiU0lEUWWyg%3D&st=2021-08-10T02%3A41%3A17Z&se=2021-08-10T10%3A51%3A17Z&sp=r', 'logs/azureml/74_azureml.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.75d4dc12-810e-42ba-ad96-dd0efbf21791/logs/azureml/74_azureml.log?sv=2019-07-07&sr=b&sig=kMv82bzWhnES4MA2H%2BU8qZA7aUv%2BBG0n6DoeKkqg8Nk%3D&st=2021-08-10T02%3A41%3A20Z&se=2021-08-10T10%3A51%3A20Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.75d4dc12-810e-42ba-ad96-dd0efbf21791/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=0WJs4WhDs3tWICh7ljcg%2Fkt1sEZ1B46yqlcJ0oKipqA%3D&st=2021-08-10T02%3A41%3A20Z&se=2021-08-10T10%3A51%3A20Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.75d4dc12-810e-42ba-ad96-dd0efbf21791/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=U1GZSodWkucLRHUTR0FcZ36KaO%2Bhbkv1T%2B8c%2FBsAZPU%3D&st=2021-08-10T02%3A41%3A20Z&se=2021-08-10T10%3A51%3A20Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.75d4dc12-810e-42ba-ad96-dd0efbf21791/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=4GlwT2s0XdFDj4CUEkv5X8aynXeobLqvblTS2xU%2BQ%2FE%3D&st=2021-08-10T02%3A41%3A20Z&se=2021-08-10T10%3A51%3A20Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.75d4dc12-810e-42ba-ad96-dd0efbf21791/logs/azureml/job_prep_azureml.log?sv=2019-07-07&sr=b&sig=pRWg%2FSJNZsveYqW3QJElxOhDgVRJJ2NOOGE3dcDQr2w%3D&st=2021-08-10T02%3A41%3A20Z&se=2021-08-10T10%3A51%3A20Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.75d4dc12-810e-42ba-ad96-dd0efbf21791/logs/azureml/job_release_azureml.log?sv=2019-07-07&sr=b&sig=v6re%2BaNlYOke%2F93%2B8DTwoFPrcW3TOv7lFt30SlkCYSc%3D&st=2021-08-10T02%3A41%3A20Z&se=2021-08-10T10%3A51%3A20Z&sp=r', 'logs/azureml/sidecar/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d/all.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.75d4dc12-810e-42ba-ad96-dd0efbf21791/logs/azureml/sidecar/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d/all.log?sv=2019-07-07&sr=b&sig=%2ByJcz6UkgEgfoXczaR%2FOnbFqk%2FjTLrn4ixP9uf3tHoo%3D&st=2021-08-10T02%3A41%3A20Z&se=2021-08-10T10%3A51%3A20Z&sp=r', 'logs/azureml/sidecar/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d/task.enter_contexts.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.75d4dc12-810e-42ba-ad96-dd0efbf21791/logs/azureml/sidecar/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d/task.enter_contexts.log?sv=2019-07-07&sr=b&sig=IQIxHT04Is67TExbB0pglDevj7PK0v%2B%2BWbWCK7pV8yU%3D&st=2021-08-10T02%3A41%3A20Z&se=2021-08-10T10%3A51%3A20Z&sp=r', 'logs/azureml/sidecar/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d/task.exit_contexts.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.75d4dc12-810e-42ba-ad96-dd0efbf21791/logs/azureml/sidecar/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d/task.exit_contexts.log?sv=2019-07-07&sr=b&sig=YDPVnz2tDAJwuXR9HIba9g2w2Qna10vcQ5HFGnwvi4w%3D&st=2021-08-10T02%3A41%3A20Z&se=2021-08-10T10%3A51%3A20Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.75d4dc12-810e-42ba-ad96-dd0efbf21791/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=ONS6jEiPAHf%2FH9LxplGf2%2FYC4Gb1KiV9T7SU1XM0shU%3D&st=2021-08-10T02%3A41%3A20Z&se=2021-08-10T10%3A51%3A20Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.75d4dc12-810e-42ba-ad96-dd0efbf21791/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=J2CkakJ56BHHMuErwNTIXS%2Fmt%2BimUOBg10O598qtgf4%3D&st=2021-08-10T02%3A41%3A20Z&se=2021-08-10T10%3A51%3A20Z&sp=r'}, 'submittedBy': 'Maggie Mhanna'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "StepRunId: 91420870-1e56-45e9-9039-e85603a441ba\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/91420870-1e56-45e9-9039-e85603a441ba?wsid=/subscriptions/2f091423-f84d-4062-8e67-1437a0c50045/resourcegroups/lis/workspaces/lis-ml&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "StepRun( Register ) Status: NotStarted\n",
      "StepRun( Register ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt\n",
      "========================================================================================================================\n",
      "2021-08-10T02:51:44Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/91420870-1e56-45e9-9039-e85603a441ba/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/91420870-1e56-45e9-9039-e85603a441ba/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=312239 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/91420870-1e56-45e9-9039-e85603a441ba/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      "2021-08-10T02:51:44Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/91420870-1e56-45e9-9039-e85603a441ba/mounts/workspaceblobstore\n",
      "2021-08-10T02:51:44Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/91420870-1e56-45e9-9039-e85603a441ba/mounts/lis_artifacts --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/91420870-1e56-45e9-9039-e85603a441ba/caches/lis_artifacts --file-cache-timeout-in-seconds=1000000 --cache-size-mb=312239 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/91420870-1e56-45e9-9039-e85603a441ba/configs/lis_artifacts.cfg --log-level=LOG_WARNING\n",
      "2021-08-10T02:51:45Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/91420870-1e56-45e9-9039-e85603a441ba/mounts/lis_artifacts\n",
      "2021-08-10T02:51:45Z Failed to start nvidia-fabricmanager due to exit status 5 with output Failed to start nvidia-fabricmanager.service: Unit nvidia-fabricmanager.service not found.\n",
      ". Please ignore this if the GPUs don't utilize NVIDIA® NVLink® switches.\n",
      "2021-08-10T02:51:45Z Starting output-watcher...\n",
      "2021-08-10T02:51:45Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-08-10T02:51:45Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2021-08-10T02:51:45Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_5572ea249a896c3014db8569f38d4a1a\n",
      "Digest: sha256:e4fcde8761b0dca23a91150bd7745746e90d05fb0e676a7adfc7e6fce5b6ce18\n",
      "Status: Image is up to date for viennaglobal.azurecr.io/azureml/azureml_5572ea249a896c3014db8569f38d4a1a:latest\n",
      "viennaglobal.azurecr.io/azureml/azureml_5572ea249a896c3014db8569f38d4a1a:latest\n",
      "2021-08-10T02:51:46Z Check if container 91420870-1e56-45e9-9039-e85603a441ba_DataSidecar already exist exited with 0, \n",
      "\n",
      "1207a899947ff40b4742493d3bfa6b70ad0a38a37d8b6d7eb970e92e255f3356\n",
      "2021-08-10T02:51:46Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      "2021-08-10T02:51:46Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-312d9e896bb7cc16de9d8c4941dccaf5-2c686d78e2457235-01 -sshRequired=false] \n",
      "2021/08/10 02:51:46 Starting App Insight Logger for task:  containerSetup\n",
      "2021/08/10 02:51:46 Version: 3.0.01676.0004 Branch: 2021-07-23 Commit: 2766ca7\n",
      "2021/08/10 02:51:46 Entered ContainerSetupTask - Preparing infiniband\n",
      "2021/08/10 02:51:46 Starting infiniband setup\n",
      "2021/08/10 02:51:46 Python Version found is Python 3.7.9\n",
      "\n",
      "2021/08/10 02:51:46 Returning Python Version as 3.7\n",
      "2021-08-10T02:51:46Z VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/08/10 02:51:46 VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/08/10 02:51:46 VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/08/10 02:51:46 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021-08-10T02:51:46Z Not setting up Infiniband in Container\n",
      "2021/08/10 02:51:46 Not setting up Infiniband in Container\n",
      "2021/08/10 02:51:46 Not setting up Infiniband in Container\n",
      "2021/08/10 02:51:46 Python Version found is Python 3.7.9\n",
      "\n",
      "2021/08/10 02:51:46 Returning Python Version as 3.7\n",
      "2021/08/10 02:51:46 sshd inside container not required for job, skipping setup.\n",
      "2021/08/10 02:51:47 All App Insights Logs was sent successfully or the close timeout of 20 was reached\n",
      "2021/08/10 02:51:47 App Insight Client has already been closed\n",
      "2021/08/10 02:51:47 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "2021-08-10T02:51:47Z Starting docker container succeeded.\n",
      "2021-08-10T02:52:00Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2021-08-10T02:52:00Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2021/08/10 02:52:01 Starting App Insight Logger for task:  runTaskLet\n",
      "2021/08/10 02:52:01 Version: 3.0.01676.0004 Branch: 2021-07-23 Commit: 2766ca7\n",
      "2021/08/10 02:52:01 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/info\n",
      "2021/08/10 02:52:01 Send process info logs to master server succeeded\n",
      "2021/08/10 02:52:01 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n",
      "2021/08/10 02:52:01 Send process info logs to master server succeeded\n",
      "[2021-08-10T02:52:01.947926] Entering context manager injector.\n",
      "[2021-08-10T02:52:02.426751] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['lis_components/register/register.py', '--model_name', 'lis-gpt2-model', '--model_dir', 'DatasetConsumptionConfig:input_f8881db2', '--register_deploy_link', '/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/91420870-1e56-45e9-9039-e85603a441ba/mounts/lis_artifacts/azureml/91420870-1e56-45e9-9039-e85603a441ba/register_deploy_link'])\n",
      "Script type = None\n",
      "[2021-08-10T02:52:02.430582] Entering Run History Context Manager.\n",
      "[2021-08-10T02:52:03.089148] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/91420870-1e56-45e9-9039-e85603a441ba/wd/azureml/91420870-1e56-45e9-9039-e85603a441ba\n",
      "[2021-08-10T02:52:03.089388] Preparing to call script [lis_components/register/register.py] with arguments:['--model_name', 'lis-gpt2-model', '--model_dir', '$input_f8881db2', '--register_deploy_link', '/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/91420870-1e56-45e9-9039-e85603a441ba/mounts/lis_artifacts/azureml/91420870-1e56-45e9-9039-e85603a441ba/register_deploy_link']\n",
      "[2021-08-10T02:52:03.089419] After variable expansion, calling script [lis_components/register/register.py] with arguments:['--model_name', 'lis-gpt2-model', '--model_dir', '/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/91420870-1e56-45e9-9039-e85603a441ba/wd/input_f8881db2_6c598996-ab02-4468-ad73-9acfbe6572cf', '--register_deploy_link', '/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/91420870-1e56-45e9-9039-e85603a441ba/mounts/lis_artifacts/azureml/91420870-1e56-45e9-9039-e85603a441ba/register_deploy_link']\n",
      "\n",
      "Loading model from /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/91420870-1e56-45e9-9039-e85603a441ba/wd/input_f8881db2_6c598996-ab02-4468-ad73-9acfbe6572cf\n",
      "2021/08/10 02:52:06 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt\n",
      "===============================================================================================================\n",
      "[2021-08-10T02:52:18.837578] Entering job release\n",
      "[2021-08-10T02:52:19.638460] Starting job release\n",
      "[2021-08-10T02:52:19.638872] Logging experiment finalizing status in history service.\n",
      "[2021-08-10T02:52:19.639059] job release stage : upload_datastore starting...Starting the daemon thread to refresh tokens in background for process with pid = 321\n",
      "\n",
      "[2021-08-10T02:52:19.639341] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-08-10T02:52:19.641551] job release stage : copy_batchai_cached_logs starting...[2021-08-10T02:52:19.641667] job release stage : execute_job_release starting...\n",
      "\n",
      "[2021-08-10T02:52:19.641810] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-08-10T02:52:19.652801] Entering context manager injector.\n",
      "[2021-08-10T02:52:19.672803] job release stage : upload_datastore completed...\n",
      "[2021-08-10T02:52:19.754614] job release stage : send_run_telemetry starting...\n",
      "[2021-08-10T02:52:19.793303] get vm size and vm region successfully.\n",
      "[2021-08-10T02:52:19.801138] get compute meta data successfully.\n",
      "[2021-08-10T02:52:19.859098] job release stage : execute_job_release completed...\n",
      "[2021-08-10T02:52:20.021270] post artifact meta request successfully.\n",
      "[2021-08-10T02:52:20.066520] upload compute record artifact successfully.\n",
      "[2021-08-10T02:52:20.066597] job release stage : send_run_telemetry completed...\n",
      "[2021-08-10T02:52:20.066868] Running in AzureML-Sidecar, starting to exit user context managers...\n",
      "[2021-08-10T02:52:20.067065] Running Sidecar release cmd...\n",
      "[2021-08-10T02:52:20.078038] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/91420870-1e56-45e9-9039-e85603a441ba/wd/azureml/91420870-1e56-45e9-9039-e85603a441ba\n",
      "Enter __exit__ of DatasetContextManager\n",
      "Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/91420870-1e56-45e9-9039-e85603a441ba/wd/input_f8881db2_6c598996-ab02-4468-ad73-9acfbe6572cf.\n",
      "fuse: failed to unmount /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/91420870-1e56-45e9-9039-e85603a441ba/wd/input_f8881db2_6c598996-ab02-4468-ad73-9acfbe6572cf: Invalid argument\n",
      "Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/91420870-1e56-45e9-9039-e85603a441ba/wd/input_f8881db2_6c598996-ab02-4468-ad73-9acfbe6572cf.\n",
      "Exit __exit__ of DatasetContextManager\n",
      "[2021-08-10T02:52:20.135083] Removing absolute paths from host...\n",
      "[2021-08-10T02:52:20.135295] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
      "[2021-08-10T02:52:20.649273] Ran Sidecar release cmd.\n",
      "[2021-08-10T02:52:20.649360] Job release is complete\n",
      "\n",
      "StepRun(Register) Execution Summary\n",
      "====================================\n",
      "StepRun( Register ) Status: Finished\n",
      "{'runId': '91420870-1e56-45e9-9039-e85603a441ba', 'target': 'pipeline-cluster', 'status': 'Completed', 'startTimeUtc': '2021-08-10T02:51:42.983102Z', 'endTimeUtc': '2021-08-10T02:52:27.941631Z', 'properties': {'ContentSnapshotId': 'f9ae6227-5f97-4b26-87c7-304c3402c618', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '348f6281-632d-4243-85c5-dfa0955d5980', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '6992e5a1', 'azureml.pipelinerunid': 'c61e6022-be86-4993-aaac-02f08f2d3152', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'azureml.RuntimeType': 'Hosttools'}, 'inputDatasets': [{'dataset': {'id': '6c598996-ab02-4468-ad73-9acfbe6572cf'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'input_f8881db2', 'mechanism': 'Mount'}}], 'outputDatasets': [], 'runDefinition': {'script': 'lis_components/register/register.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--model_name', '$AML_PARAMETER_aml_model_name', '--model_dir', 'DatasetConsumptionConfig:input_f8881db2', '--register_deploy_link', '$AZUREML_DATAREFERENCE_register_deploy_link'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'pipeline-cluster', 'dataReferences': {'register_deploy_link': {'dataStoreName': 'lis_artifacts', 'mode': 'Mount', 'pathOnDataStore': 'azureml/91420870-1e56-45e9-9039-e85603a441ba/register_deploy_link', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'input_f8881db2': {'dataLocation': {'dataset': {'id': '6c598996-ab02-4468-ad73-9acfbe6572cf', 'name': None, 'version': None}, 'dataPath': None, 'uri': None}, 'mechanism': 'Mount', 'environmentVariableName': 'input_f8881db2', 'pathOnCompute': None, 'overwrite': False}}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'pipeline-env', 'version': 'Autosave_2021-08-09T13:40:51Z_738b2e1a', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'dependencies': ['python=3.6.9', 'pip', {'pip': ['transformers == 3.5.1', 'datasets == 1.10.2', 'tensorflow == 2.5.0', 'azureml-defaults==1.30.0']}], 'name': 'azureml_82f5617ca19cd57b18cafd61c017ea7a'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210531.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'AISupercomputer.D2', 'imageVersion': 'pytorch-1.7.0', 'location': 'westus2', 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard'}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {'AML_PARAMETER_aml_model_name': 'lis-gpt2-model'}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.91420870-1e56-45e9-9039-e85603a441ba/azureml-logs/55_azureml-execution-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt?sv=2019-07-07&sr=b&sig=ZN8Far3bQaaLEMzcMo%2ByLHopXfP8QjYv%2FpTWa54njuM%3D&st=2021-08-10T02%3A42%3A22Z&se=2021-08-10T10%3A52%3A22Z&sp=r', 'azureml-logs/65_job_prep-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.91420870-1e56-45e9-9039-e85603a441ba/azureml-logs/65_job_prep-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt?sv=2019-07-07&sr=b&sig=EVj9Dsmjt9SE0oslL203fmKQ%2FtlQkjfhJOj3JoGVqXs%3D&st=2021-08-10T02%3A42%3A22Z&se=2021-08-10T10%3A52%3A22Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.91420870-1e56-45e9-9039-e85603a441ba/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=LWY7Y6eQS32HNwILEG7pRj5BbHlncgfWFTPcmUWdehU%3D&st=2021-08-10T02%3A42%3A22Z&se=2021-08-10T10%3A52%3A22Z&sp=r', 'azureml-logs/75_job_post-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.91420870-1e56-45e9-9039-e85603a441ba/azureml-logs/75_job_post-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt?sv=2019-07-07&sr=b&sig=jmbkxuCRwtFNsLT7He6RPGrQJ4FExOv1AssqJnIcoyc%3D&st=2021-08-10T02%3A42%3A22Z&se=2021-08-10T10%3A52%3A22Z&sp=r', 'azureml-logs/process_info.json': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.91420870-1e56-45e9-9039-e85603a441ba/azureml-logs/process_info.json?sv=2019-07-07&sr=b&sig=PkKNNcHVUXuuYjVJdEamcho1O1fJz10NVQ56X9Ojb0Y%3D&st=2021-08-10T02%3A42%3A22Z&se=2021-08-10T10%3A52%3A22Z&sp=r', 'azureml-logs/process_status.json': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.91420870-1e56-45e9-9039-e85603a441ba/azureml-logs/process_status.json?sv=2019-07-07&sr=b&sig=YTgQYXjwKE97yE9a71uBc%2B3Y%2BTjTAj49QgUxQhsSe1Q%3D&st=2021-08-10T02%3A42%3A22Z&se=2021-08-10T10%3A52%3A22Z&sp=r', 'logs/azureml/80_azureml.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.91420870-1e56-45e9-9039-e85603a441ba/logs/azureml/80_azureml.log?sv=2019-07-07&sr=b&sig=c7NbwDEPC7wQofkKF2ToY4PCSawHHWeCwL6uRCghRhM%3D&st=2021-08-10T02%3A42%3A22Z&se=2021-08-10T10%3A52%3A22Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.91420870-1e56-45e9-9039-e85603a441ba/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=9wqnL67%2BXNKdLEkmtvtnLTHs8zyw%2BqXGq7G7A0EHIqE%3D&st=2021-08-10T02%3A42%3A22Z&se=2021-08-10T10%3A52%3A22Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.91420870-1e56-45e9-9039-e85603a441ba/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=lxGxJyNOovGYbY1NMXYEo5P1SOC0M8%2F6oYPakoe0fGc%3D&st=2021-08-10T02%3A42%3A22Z&se=2021-08-10T10%3A52%3A22Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.91420870-1e56-45e9-9039-e85603a441ba/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=UGcahB912vb0pISngpWhMtrqpVdJoi1MDYAyVtT3dbQ%3D&st=2021-08-10T02%3A42%3A22Z&se=2021-08-10T10%3A52%3A22Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.91420870-1e56-45e9-9039-e85603a441ba/logs/azureml/job_prep_azureml.log?sv=2019-07-07&sr=b&sig=MFib0FX6b1GPjJw1i%2FJkyyXmzgN13GUJCFWiL8ec80k%3D&st=2021-08-10T02%3A42%3A22Z&se=2021-08-10T10%3A52%3A22Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.91420870-1e56-45e9-9039-e85603a441ba/logs/azureml/job_release_azureml.log?sv=2019-07-07&sr=b&sig=F6kqmTtzZ%2F%2Feja9VVdtVe7eWyGIcaJsTgagrvjzpLXQ%3D&st=2021-08-10T02%3A42%3A22Z&se=2021-08-10T10%3A52%3A22Z&sp=r', 'logs/azureml/sidecar/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d/all.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.91420870-1e56-45e9-9039-e85603a441ba/logs/azureml/sidecar/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d/all.log?sv=2019-07-07&sr=b&sig=4qrTHSNe%2BgQVf791m%2FN0PXDcK%2Ffx3IKth7KTxFCiD1A%3D&st=2021-08-10T02%3A42%3A22Z&se=2021-08-10T10%3A52%3A22Z&sp=r', 'logs/azureml/sidecar/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d/task.enter_contexts.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.91420870-1e56-45e9-9039-e85603a441ba/logs/azureml/sidecar/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d/task.enter_contexts.log?sv=2019-07-07&sr=b&sig=s3TlCzMDvySIlo6azqd%2BoxQYgXk6K6cMf%2FwwQ8aNBuA%3D&st=2021-08-10T02%3A42%3A22Z&se=2021-08-10T10%3A52%3A22Z&sp=r', 'logs/azureml/sidecar/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d/task.exit_contexts.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.91420870-1e56-45e9-9039-e85603a441ba/logs/azureml/sidecar/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d/task.exit_contexts.log?sv=2019-07-07&sr=b&sig=Kdg0S5lqhsHeVl5ifeuOmqdn19yDTrQX2xqxF7vKH98%3D&st=2021-08-10T02%3A42%3A22Z&se=2021-08-10T10%3A52%3A22Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.91420870-1e56-45e9-9039-e85603a441ba/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=dhyug6Xrta4qlCYZl%2FG%2Fq43bk44wZrbHq5qSFkRsQMo%3D&st=2021-08-10T02%3A42%3A22Z&se=2021-08-10T10%3A52%3A22Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.91420870-1e56-45e9-9039-e85603a441ba/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=3oG7xgG%2FN3JDRgz73%2FpL%2Be8enc8BOXNsrk5Zojq%2FXMo%3D&st=2021-08-10T02%3A42%3A22Z&se=2021-08-10T10%3A52%3A22Z&sp=r'}, 'submittedBy': 'Maggie Mhanna'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "StepRunId: 7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0?wsid=/subscriptions/2f091423-f84d-4062-8e67-1437a0c50045/resourcegroups/lis/workspaces/lis-ml&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "StepRun( Deploy ) Status: NotStarted\n",
      "StepRun( Deploy ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt\n",
      "========================================================================================================================\n",
      "2021-08-10T02:52:44Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=312239 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      "2021-08-10T02:52:44Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/mounts/workspaceblobstore\n",
      "2021-08-10T02:52:44Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/mounts/lis_artifacts --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/caches/lis_artifacts --file-cache-timeout-in-seconds=1000000 --cache-size-mb=312239 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/configs/lis_artifacts.cfg --log-level=LOG_WARNING\n",
      "2021-08-10T02:52:45Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/mounts/lis_artifacts\n",
      "2021-08-10T02:52:45Z Failed to start nvidia-fabricmanager due to exit status 5 with output Failed to start nvidia-fabricmanager.service: Unit nvidia-fabricmanager.service not found.\n",
      ". Please ignore this if the GPUs don't utilize NVIDIA® NVLink® switches.\n",
      "2021-08-10T02:52:45Z Starting output-watcher...\n",
      "2021-08-10T02:52:45Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-08-10T02:52:45Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2021-08-10T02:52:45Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_3106eac23ddd7603fa7dab2694eb52ff\n",
      "Digest: sha256:64071389a06820223142eabd61e1b4bfd5e0b450131c8a50eef3c745fad8a73e\n",
      "Status: Image is up to date for 29bfa99a8943410c8e0210fa3a3417f5.azurecr.io/azureml/azureml_3106eac23ddd7603fa7dab2694eb52ff:latest\n",
      "29bfa99a8943410c8e0210fa3a3417f5.azurecr.io/azureml/azureml_3106eac23ddd7603fa7dab2694eb52ff:latest\n",
      "2021-08-10T02:52:46Z Check if container 7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0 already exist exited with 0, \n",
      "\n",
      "e9585da2ad72a78532cf4089ff811301901db9dbe911fbc62ef5151ff34cc9fb\n",
      "2021-08-10T02:52:46Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      "2021-08-10T02:52:46Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-27a9339aa43eb839ca862761c68b229c-05b515f374e0a16f-01 -sshRequired=false] \n",
      "2021/08/10 02:52:46 Starting App Insight Logger for task:  containerSetup\n",
      "2021/08/10 02:52:46 Version: 3.0.01676.0004 Branch: 2021-07-23 Commit: 2766ca7\n",
      "2021/08/10 02:52:46 Entered ContainerSetupTask - Preparing infiniband\n",
      "2021/08/10 02:52:46 Starting infiniband setup\n",
      "2021/08/10 02:52:46 Python Version found is Python 3.6.9 :: Anaconda, Inc.\n",
      "\n",
      "2021/08/10 02:52:46 Returning Python Version as 3.6\n",
      "2021-08-10T02:52:46Z VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n",
      "2021/08/10 02:52:46 VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n",
      "2021/08/10 02:52:46 VMSize: standard_nc6, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n",
      "2021/08/10 02:52:46 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021-08-10T02:52:46Z Not setting up Infiniband in Container\n",
      "2021/08/10 02:52:46 Not setting up Infiniband in Container\n",
      "2021/08/10 02:52:46 Not setting up Infiniband in Container\n",
      "2021/08/10 02:52:46 Python Version found is Python 3.6.9 :: Anaconda, Inc.\n",
      "\n",
      "2021/08/10 02:52:46 Returning Python Version as 3.6\n",
      "2021/08/10 02:52:46 sshd inside container not required for job, skipping setup.\n",
      "2021/08/10 02:52:46 All App Insights Logs was sent successfully or the close timeout of 20 was reached\n",
      "2021/08/10 02:52:46 App Insight Client has already been closed\n",
      "2021/08/10 02:52:46 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "2021-08-10T02:52:47Z Starting docker container succeeded.\n",
      "2021-08-10T02:52:50Z Job environment preparation succeeded on 10.0.0.4. Output: \n",
      ">>>   2021/08/10 02:52:44 Starting App Insight Logger for task:  prepareJobEnvironment\n",
      ">>>   2021/08/10 02:52:44 Version: 3.0.01676.0004 Branch: 2021-07-23 Commit: 2766ca7\n",
      ">>>   2021/08/10 02:52:44 runtime.GOOS linux\n",
      ">>>   2021/08/10 02:52:44 Checking if '/tmp' exists\n",
      ">>>   2021/08/10 02:52:44 Reading dyanamic configs\n",
      ">>>   2021/08/10 02:52:44 Container sas url: https://baiscriptswesteuropeprod.blob.core.windows.net/aihosttools?sv=2018-03-28&sr=c&si=aihosttoolspolicy&sig=9UBH7ig8b9NIeIkNQpNxDmP7wUMtSqFoIE5AY22cheE%3D\n",
      ">>>   2021/08/10 02:52:44 Failed to read from file /mnt/batch/tasks/startup/wd/az_resource/azsecpack.variables, open /mnt/batch/tasks/startup/wd/az_resource/azsecpack.variables: no such file or directory\n",
      ">>>   2021/08/10 02:52:44 [in autoUpgradeFromJobNodeSetup] Is Azsecpack installer on host: true. Is Azsecpack installation enabled: false,\n",
      ">>>   2021/08/10 02:52:44 Starting Azsecpack installation on machine: f585a493cfbe4c568aa6cd957b0778e8000000#72f988bf-86f1-41af-91ab-2d7cd011db47#2f091423-f84d-4062-8e67-1437a0c50045#lis#lis-ml#pipeline-cluster#tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d\n",
      ">>>   2021/08/10 02:52:44 Is Azsecpack enabled: false, GetDisableVsatlsscan: true\n",
      ">>>   2021/08/10 02:52:44 Turning off azsecpack, if it is already running\n",
      ">>>   2021/08/10 02:52:44 [doTurnOffAzsecpack] output:Unit mdsd.service could not be found.\n",
      ">>>   ,err:exit status 1.\n",
      ">>>   2021/08/10 02:52:44 OS patching disabled by dynamic configs. Skipping.\n",
      ">>>   2021/08/10 02:52:44 Job: AZ_BATCHAI_JOB_NAME does not turn on the DetonationChamber\n",
      ">>>   2021/08/10 02:52:44 Start to getting gpu count by running nvidia-smi command\n",
      ">>>   2021/08/10 02:52:44 GPU : GPU 0: Tesla K80 (UUID: GPU-eb1eb5f7-c0f6-673d-3921-76662ebdb48b)\n",
      ">>>   2021/08/10 02:52:44 GPU count found on the node: 1\n",
      ">>>   2021/08/10 02:52:44 Mellanox Inbox drivers found (implying presence of SR-IOV)?: false\n",
      ">>>   2021/08/10 02:52:44 Disabling IB for NCCL.\n",
      ">>>   2021/08/10 02:52:44 AMLComputeXDSEndpoint:  https://westeurope-prodk8ds.batchai.core.windows.net\n",
      ">>>   2021/08/10 02:52:44 AMLComputeXDSApiVersion:  2018-02-01\n",
      ">>>   2021/08/10 02:52:44 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/config\n",
      ">>>   2021/08/10 02:52:44 This is not a aml-workstation (compute instance), current offer type: amlcompute. Starting identity responder as part of prepareJobEnvironment.\n",
      ">>>   2021/08/10 02:52:44 Starting identity responder.\n",
      ">>>   2021/08/10 02:52:44 Starting identity responder.\n",
      ">>>   2021/08/10 02:52:44 Logfile used for identity responder: /mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/7d10fa18-24d5-4b92-a_f5652795-0722-4249-84f0-442f645fe95d/IdentityResponderLog-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt\n",
      ">>>   2021/08/10 02:52:44 Logfile used for identity responder: /mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/7d10fa18-24d5-4b92-a_f5652795-0722-4249-84f0-442f645fe95d/IdentityResponderLog-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt\n",
      ">>>   2021/08/10 02:52:44 Started Identity Responder for job.\n",
      ">>>   2021/08/10 02:52:44 Started Identity Responder for job.\n",
      ">>>   2021/08/10 02:52:44 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd\n",
      ">>>   2021/08/10 02:52:44 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/shared\n",
      ">>>   2021/08/10 02:52:44 From the policy service, the filtering patterns is: , data store is \n",
      ">>>   2021/08/10 02:52:44 Mounting job level file systems\n",
      ">>>   2021/08/10 02:52:44 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/mounts\n",
      ">>>   2021/08/10 02:52:44 Attempting to read datastore credentials file: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/config/.amlcompute.datastorecredentials\n",
      ">>>   2021/08/10 02:52:44 Datastore credentials file not found, skipping.\n",
      ">>>   2021/08/10 02:52:44 Attempting to read runtime sas tokens file: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/config/.master.runtimesastokens\n",
      ">>>   2021/08/10 02:52:44 Runtime sas tokens file not found, skipping.\n",
      ">>>   2021/08/10 02:52:44 Mounting NFS servers\n",
      ">>>   2021/08/10 02:52:44 No Azure File Shares configured\n",
      ">>>   2021/08/10 02:52:44 Mounting blob file systems\n",
      ">>>   2021/08/10 02:52:44 Blobfuse runtime version 1.3.6\n",
      ">>>   2021/08/10 02:52:44 Mounting azureml-blobstore-29bfa99a-8943-410c-8e02-10fa3a3417f5 container from lisml8132196936 account at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/mounts/workspaceblobstore\n",
      ">>>   2021/08/10 02:52:44 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/08/10 02:52:44 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/08/10 02:52:44 Blobfuse cache size set to 312239 MB.\n",
      ">>>   2021/08/10 02:52:44 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=312239 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      ">>>   2021/08/10 02:52:44 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/mounts/workspaceblobstore\n",
      ">>>   2021/08/10 02:52:44 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/mounts/workspaceblobstore\n",
      ">>>   2021/08/10 02:52:44 Successfully mounted azureml-blobstore-29bfa99a-8943-410c-8e02-10fa3a3417f5 container from lisml8132196936 account at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/mounts/workspaceblobstore\n",
      ">>>   2021/08/10 02:52:44 Failed to created run_id directory: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/mounts/workspaceblobstore/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0, due to mkdir /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/mounts/workspaceblobstore/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0: read-only file system\n",
      ">>>   2021/08/10 02:52:44 Mounting lis-artifacts container from lisml8132196936 account at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/mounts/lis_artifacts\n",
      ">>>   2021/08/10 02:52:44 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/08/10 02:52:44 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/08/10 02:52:44 Blobfuse cache size set to 312239 MB.\n",
      ">>>   2021/08/10 02:52:44 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/mounts/lis_artifacts --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/caches/lis_artifacts --file-cache-timeout-in-seconds=1000000 --cache-size-mb=312239 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/configs/lis_artifacts.cfg --log-level=LOG_WARNING\n",
      ">>>   2021/08/10 02:52:45 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/mounts/lis_artifacts\n",
      ">>>   2021/08/10 02:52:45 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/mounts/lis_artifacts\n",
      ">>>   2021/08/10 02:52:45 Successfully mounted lis-artifacts container from lisml8132196936 account at /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/mounts/lis_artifacts\n",
      ">>>   2021/08/10 02:52:45 Created run_id directory: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/mounts/lis_artifacts/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0\n",
      ">>>   2021/08/10 02:52:45 No unmanaged file systems configured\n",
      ">>>   2021/08/10 02:52:45 Start to getting gpu count by running nvidia-smi command\n",
      ">>>   2021/08/10 02:52:45 GPU : GPU 0: Tesla K80 (UUID: GPU-eb1eb5f7-c0f6-673d-3921-76662ebdb48b)\n",
      ">>>   2021/08/10 02:52:45 Failed to start nvidia-fabricmanager due to exit status 5 with output Failed to start nvidia-fabricmanager.service: Unit nvidia-fabricmanager.service not found.\n",
      ">>>   . Please ignore this if the GPUs don't utilize NVIDIA® NVLink® switches.\n",
      ">>>   2021/08/10 02:52:45 Failed to start nvidia-fabricmanager due to exit status 5 with output Failed to start nvidia-fabricmanager.service: Unit nvidia-fabricmanager.service not found.\n",
      ">>>   . Please ignore this if the GPUs don't utilize NVIDIA® NVLink® switches.\n",
      ">>>   2021/08/10 02:52:45 From the policy service, the filtering patterns is: , data store is \n",
      ">>>   2021/08/10 02:52:45 Creating working directory: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0\n",
      ">>>   2021/08/10 02:52:45 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0\n",
      ">>>   2021/08/10 02:52:45 Changing permissions for all existing files under directory: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0\n",
      ">>>   2021/08/10 02:52:45 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0\n",
      ">>>   2021/08/10 02:52:45 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/azureml_compute_logs\n",
      ">>>   2021/08/10 02:52:45 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/azureml_compute_logs/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d\n",
      ">>>   2021/08/10 02:52:45 Change mode to 666 for file /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/azureml_compute_logs/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d/55_azureml-execution-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt\n",
      ">>>   2021/08/10 02:52:45 Set default ACL for files under directory by running: /usr/bin/setfacl -m default:g::rwx -m default:o::rwx /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0\n",
      ">>>   2021/08/10 02:52:45 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/azureml_compute_logs\n",
      ">>>   2021/08/10 02:52:45 Changing permissions for all existing files under directory: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/azureml_compute_logs\n",
      ">>>   2021/08/10 02:52:45 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/azureml_compute_logs\n",
      ">>>   2021/08/10 02:52:45 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/azureml_compute_logs/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d\n",
      ">>>   2021/08/10 02:52:45 Change mode to 666 for file /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/azureml_compute_logs/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d/55_azureml-execution-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt\n",
      ">>>   2021/08/10 02:52:45 Set default ACL for files under directory by running: /usr/bin/setfacl -m default:g::rwx -m default:o::rwx /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/azureml_compute_logs\n",
      ">>>   2021/08/10 02:52:45 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/logs\n",
      ">>>   2021/08/10 02:52:45 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/outputs\n",
      ">>>   2021/08/10 02:52:45 Starting output-watcher...\n",
      ">>>   2021/08/10 02:52:45 Single file input dataset is enabled.\n",
      ">>>   2021/08/10 02:52:45 Start to pulling docker image: 29bfa99a8943410c8e0210fa3a3417f5.azurecr.io/azureml/azureml_3106eac23ddd7603fa7dab2694eb52ff\n",
      ">>>   2021/08/10 02:52:45 Start pull docker image: 29bfa99a8943410c8e0210fa3a3417f5.azurecr.io\n",
      ">>>   2021/08/10 02:52:45 Getting credentials for image 29bfa99a8943410c8e0210fa3a3417f5.azurecr.io/azureml/azureml_3106eac23ddd7603fa7dab2694eb52ff with url 29bfa99a8943410c8e0210fa3a3417f5.azurecr.io\n",
      ">>>   2021/08/10 02:52:45 Container registry is ACR.\n",
      ">>>   2021/08/10 02:52:45 Skip getting ACR Credentials from Identity and will be getting it from EMS\n",
      ">>>   2021/08/10 02:52:45 Getting ACR Credentials from EMS for environment pipeline-env:Autosave_2021-08-09T13:40:51Z_738b2e1a\n",
      ">>>   2021/08/10 02:52:45 Requesting XDS for registry details.\n",
      ">>>   2021/08/10 02:52:45 Attempt 1 of http call to https://westeurope-prodk8ds.batchai.core.windows.net/hosttoolapi/subscriptions/2f091423-f84d-4062-8e67-1437a0c50045/resourceGroups/lis/workspaces/lis-ml/clusters/pipeline-cluster/nodes/tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d?api-version=2018-02-01\n",
      ">>>   2021/08/10 02:52:45 Got container registry details from credentials service for registry address: 29bfa99a8943410c8e0210fa3a3417f5.azurecr.io.\n",
      ">>>   2021/08/10 02:52:45 Writing ACR Details to file...\n",
      ">>>   2021/08/10 02:52:45 Copying ACR Details file to worker nodes...\n",
      ">>>   2021/08/10 02:52:45 Executing 'Copy ACR Details file' on 10.0.0.4\n",
      ">>>   2021/08/10 02:52:45 Begin executing 'Copy ACR Details file' task on Node\n",
      ">>>   2021/08/10 02:52:45 'Copy ACR Details file' task Node result: succeeded\n",
      ">>>   2021/08/10 02:52:45 Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   >>>   \n",
      ">>>   >>>   \n",
      ">>>   2021/08/10 02:52:45 Successfully retrieved ACR Credentials from EMS.\n",
      ">>>   2021/08/10 02:52:45 EMS returned 29bfa99a8943410c8e0210fa3a3417f5.azurecr.io for environment pipeline-env\n",
      ">>>   2021/08/10 02:52:45 Save docker credentials for image 29bfa99a8943410c8e0210fa3a3417f5.azurecr.io/azureml/azureml_3106eac23ddd7603fa7dab2694eb52ff in /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd/docker_login_4F1E9C47F839AF4A\n",
      ">>>   2021/08/10 02:52:45 Start login to the docker registry\n",
      ">>>   2021/08/10 02:52:45 Successfully logged into the docker registry.\n",
      ">>>   2021/08/10 02:52:45 Start run pull docker image command\n",
      ">>>   2021/08/10 02:52:45 Pull docker image succeeded.\n",
      ">>>   2021/08/10 02:52:45 Removed docker config dir /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd/docker_login_4F1E9C47F839AF4A\n",
      ">>>   2021/08/10 02:52:45 Pull docker image time: 518.384296ms\n",
      ">>>   \n",
      ">>>   2021/08/10 02:52:46 Docker Version that this nodes use are: 19.03.14+azure\n",
      ">>>   \n",
      ">>>   2021/08/10 02:52:46 Start to getting gpu count by running nvidia-smi command\n",
      ">>>   2021/08/10 02:52:46 GPU : GPU 0: Tesla K80 (UUID: GPU-eb1eb5f7-c0f6-673d-3921-76662ebdb48b)\n",
      ">>>   2021/08/10 02:52:46 Setting the memory limit for docker container to be 55987 MB\n",
      ">>>   2021/08/10 02:52:46 The env variable file size is 41546 bytes\n",
      ">>>   2021/08/10 02:52:46 Creating parent cgroup '7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0' for Containers used in Job\n",
      ">>>   2021/08/10 02:52:46 Add parent cgroup '7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0' to container '7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0'\n",
      ">>>   2021/08/10 02:52:46 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      ">>>   2021/08/10 02:52:46 Original Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/7d10fa18-24d5-4b92-a_f5652795-0722-4249-84f0-442f645fe95d/certs:/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/7d10fa18-24d5-4b92-a_f5652795-0722-4249-84f0-442f645fe95d/certs,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,--gpus,all,-m,55987m,-v,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/azureml_compute_logs,-v,/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/7d10fa18-24d5-4b92-a_f5652795-0722-4249-84f0-442f645fe95d/wd:/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/7d10fa18-24d5-4b92-a_f5652795-0722-4249-84f0-442f645fe95d/wd,-v,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0:/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0,-v,/mnt/batch/tasks/shared/LS_root/shared/tracing/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/logs/azureml/tracing,-w,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/config/.batchai.envlist,--cgroup-parent=/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/,--shm-size,2g\n",
      ">>>   2021/08/10 02:52:46 the binding /mnt/batch/tasks/shared/LS_root/shared/tracing/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/logs/azureml/tracing is discarded as we already have /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared \n",
      ">>>   2021/08/10 02:52:46 the binding /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/azureml_compute_logs is discarded as we already have /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0:/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0 \n",
      ">>>   2021/08/10 02:52:46 Updated Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0,--gpus,all,-m,55987m,-w,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/config/.batchai.envlist,--cgroup-parent=/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/,--shm-size,2g,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0:/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0,-v,/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/7d10fa18-24d5-4b92-a_f5652795-0722-4249-84f0-442f645fe95d/wd:/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/7d10fa18-24d5-4b92-a_f5652795-0722-4249-84f0-442f645fe95d/wd,-v,/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/7d10fa18-24d5-4b92-a_f5652795-0722-4249-84f0-442f645fe95d/certs:/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/7d10fa18-24d5-4b92-a_f5652795-0722-4249-84f0-442f645fe95d/certs\n",
      ">>>   2021/08/10 02:52:46 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name 7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0 --gpus all -m 55987m -w /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/config/.batchai.envlist --cgroup-parent=/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/ --shm-size 2g -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0:/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0 -v /mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/7d10fa18-24d5-4b92-a_f5652795-0722-4249-84f0-442f645fe95d/wd:/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/7d10fa18-24d5-4b92-a_f5652795-0722-4249-84f0-442f645fe95d/wd -v /mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/7d10fa18-24d5-4b92-a_f5652795-0722-4249-84f0-442f645fe95d/certs:/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/7d10fa18-24d5-4b92-a_f5652795-0722-4249-84f0-442f645fe95d/certs -d -it --privileged --net=host 29bfa99a8943410c8e0210fa3a3417f5.azurecr.io/azureml/azureml_3106eac23ddd7603fa7dab2694eb52ff\n",
      ">>>   2021/08/10 02:52:46 Check if container 7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0 already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2021/08/10 02:52:46 Check if container 7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0 already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2021/08/10 02:52:46 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      ">>>   2021/08/10 02:52:46 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      ">>>   2021/08/10 02:52:46 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-27a9339aa43eb839ca862761c68b229c-05b515f374e0a16f-01 -sshRequired=false] \n",
      ">>>   2021/08/10 02:52:46 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-27a9339aa43eb839ca862761c68b229c-05b515f374e0a16f-01 -sshRequired=false] \n",
      ">>>   2021/08/10 02:52:47 Container ssh is not required for job type.\n",
      ">>>   2021/08/10 02:52:47 Starting docker container succeeded.\n",
      ">>>   2021/08/10 02:52:47 Starting docker container succeeded.\n",
      ">>>   2021/08/10 02:52:47 Disk space after starting docker container: 319572MB\n",
      ">>>   2021/08/10 02:52:47 Begin execution of runSpecialJobTask\n",
      ">>>   2021/08/10 02:52:47 Creating directory at $AZUREML_LOGDIRECTORY_PATH\n",
      ">>>   2021/08/10 02:52:47 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/azureml-logs\n",
      ">>>   2021/08/10 02:52:47 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/azureml_compute_logs\n",
      ">>>   2021/08/10 02:52:47 runSpecialJobTask: Raw cmd for preparation is passed is: /azureml-envs/azureml_82f5617ca19cd57b18cafd61c017ea7a/bin/python /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/mounts/workspaceblobstore/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"f9ae6227-5f97-4b26-87c7-304c3402c618\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/08/10 02:52:47 runSpecialJobTask: stdout path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/azureml_compute_logs/65_job_prep-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt\n",
      ">>>   2021/08/10 02:52:47 runSpecialJobTask: stderr path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/azureml_compute_logs/65_job_prep-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt\n",
      ">>>   2021/08/10 02:52:47 native cmd: export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/7d10fa18-24d5-4b92-a_f5652795-0722-4249-84f0-442f645fe95d/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0;/azureml-envs/azureml_82f5617ca19cd57b18cafd61c017ea7a/bin/python /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/mounts/workspaceblobstore/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"f9ae6227-5f97-4b26-87c7-304c3402c618\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/08/10 02:52:47 runSpecialJobTask: commons.GetOsPlatform(): ubuntu\n",
      ">>>   2021/08/10 02:52:47 runSpecialJobTask: Running cmd: /usr/bin/docker exec -e AZUREML_SDK_TRACEPARENT=00-27a9339aa43eb839ca862761c68b229c-12c3c4dfe617c2f3-01 -t 7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0 bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1='$'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/94d71bf7-e0a2-46eb-b12e-73a94804b983/job-1/7d10fa18-24d5-4b92-a_f5652795-0722-4249-84f0-442f645fe95d/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0;/azureml-envs/azureml_82f5617ca19cd57b18cafd61c017ea7a/bin/python /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/mounts/workspaceblobstore/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"f9ae6227-5f97-4b26-87c7-304c3402c618\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/08/10 02:52:49 Attempt 1 of http call to https://westeurope.api.azureml.ms/history/v1.0/private/subscriptions/2f091423-f84d-4062-8e67-1437a0c50045/resourceGroups/lis/providers/Microsoft.MachineLearningServices/workspaces/lis-ml/runs/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/spans\n",
      ">>>   2021/08/10 02:52:49 runSpecialJobTask: job preparation exited with code 0 and err <nil>\n",
      ">>>   \n",
      ">>>   2021/08/10 02:52:49 runSpecialJobTask: preparation: [2021-08-10T02:52:47.437691] Entering job preparation.\n",
      ">>>   2021/08/10 02:52:49 runSpecialJobTask: preparation: [2021-08-10T02:52:48.839539] Starting job preparation.\n",
      ">>>   2021/08/10 02:52:49 runSpecialJobTask: preparation: [2021-08-10T02:52:48.839575] Extracting the control code.\n",
      ">>>   2021/08/10 02:52:49 runSpecialJobTask: preparation: [2021-08-10T02:52:48.839874] Starting extract_project.\n",
      ">>>   2021/08/10 02:52:49 runSpecialJobTask: preparation: [2021-08-10T02:52:48.839929] Starting to extract zip file.\n",
      ">>>   2021/08/10 02:52:49 runSpecialJobTask: preparation: [2021-08-10T02:52:48.860125] Finished extracting zip file.\n",
      ">>>   2021/08/10 02:52:49 runSpecialJobTask: preparation: [2021-08-10T02:52:48.863795] Using urllib.request Python 3.0 or later\n",
      ">>>   2021/08/10 02:52:49 runSpecialJobTask: preparation: [2021-08-10T02:52:48.863836] Start fetching snapshots.\n",
      ">>>   2021/08/10 02:52:49 runSpecialJobTask: preparation: [2021-08-10T02:52:48.863871] Start fetching snapshot.\n",
      ">>>   2021/08/10 02:52:49 runSpecialJobTask: preparation: [2021-08-10T02:52:48.863886] Retrieving project from snapshot: f9ae6227-5f97-4b26-87c7-304c3402c618\n",
      ">>>   2021/08/10 02:52:49 runSpecialJobTask: preparation: Starting the daemon thread to refresh tokens in background for process with pid = 45\n",
      ">>>   2021/08/10 02:52:49 runSpecialJobTask: preparation: [2021-08-10T02:52:49.340797] Finished fetching snapshot.\n",
      ">>>   2021/08/10 02:52:49 runSpecialJobTask: preparation: [2021-08-10T02:52:49.340828] Finished fetching snapshots.\n",
      ">>>   2021/08/10 02:52:49 runSpecialJobTask: preparation: [2021-08-10T02:52:49.340834] Finished extract_project.\n",
      ">>>   2021/08/10 02:52:49 runSpecialJobTask: preparation: [2021-08-10T02:52:49.340933] Finished fetching and extracting the control code.\n",
      ">>>   2021/08/10 02:52:49 runSpecialJobTask: preparation: [2021-08-10T02:52:49.344505] downloadDataStore - Download from datastores if requested.\n",
      ">>>   2021/08/10 02:52:49 runSpecialJobTask: preparation: [2021-08-10T02:52:49.345338] Start run_history_prep.\n",
      ">>>   2021/08/10 02:52:49 runSpecialJobTask: preparation: [2021-08-10T02:52:49.357043] Entering context manager injector.\n",
      ">>>   2021/08/10 02:52:49 runSpecialJobTask: preparation: Acquired lockfile /tmp/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0-datastore.lock to downloading input data references\n",
      ">>>   2021/08/10 02:52:49 runSpecialJobTask: preparation: [2021-08-10T02:52:49.798530] downloadDataStore completed\n",
      ">>>   2021/08/10 02:52:49 runSpecialJobTask: preparation: [2021-08-10T02:52:49.801122] Job preparation is complete.\n",
      ">>>   2021/08/10 02:52:49 Execution of runSpecialJobTask completed\n",
      ">>>   2021/08/10 02:52:49 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      ">>>   Stopped: false\n",
      ">>>   OriginalData: 3\n",
      ">>>   FilteredData: 0.\n",
      ">>>   2021/08/10 02:52:49 Process Exiting with Code:  0\n",
      ">>>   2021/08/10 02:52:50 All App Insights Logs was sent successfully or the close timeout of 20 was reached\n",
      ">>>   \n",
      "2021-08-10T02:52:50Z 127.0.0.1 slots=1 max-slots=1\n",
      "2021-08-10T02:52:50Z launching Custom job\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2021/08/10 02:52:50 Starting App Insight Logger for task:  runTaskLet\n",
      "2021/08/10 02:52:50 Version: 3.0.01676.0004 Branch: 2021-07-23 Commit: 2766ca7\n",
      "2021/08/10 02:52:50 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/info\n",
      "2021/08/10 02:52:50 Send process info logs to master server succeeded\n",
      "2021/08/10 02:52:50 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n",
      "2021/08/10 02:52:50 Send process info logs to master server succeeded\n",
      "[2021-08-10T02:52:50.627734] Entering context manager injector.\n",
      "[2021-08-10T02:52:51.108284] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['lis_components/deploy/deploy.py', '--service_name', 'lis-gpt2-serviceapp', '--model_name', 'lis-gpt2-model', '--cpu_cores', '1', '--memory_gb', '2', '--register_deploy_link', '/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/mounts/lis_artifacts/azureml/91420870-1e56-45e9-9039-e85603a441ba/register_deploy_link'])\n",
      "Script type = None\n",
      "[2021-08-10T02:52:51.112061] Entering Run History Context Manager.\n",
      "[2021-08-10T02:52:51.767952] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/wd/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0\n",
      "[2021-08-10T02:52:51.768172] Preparing to call script [lis_components/deploy/deploy.py] with arguments:['--service_name', 'lis-gpt2-serviceapp', '--model_name', 'lis-gpt2-model', '--cpu_cores', '1', '--memory_gb', '2', '--register_deploy_link', '/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/mounts/lis_artifacts/azureml/91420870-1e56-45e9-9039-e85603a441ba/register_deploy_link']\n",
      "[2021-08-10T02:52:51.768200] After variable expansion, calling script [lis_components/deploy/deploy.py] with arguments:['--service_name', 'lis-gpt2-serviceapp', '--model_name', 'lis-gpt2-model', '--cpu_cores', '1', '--memory_gb', '2', '--register_deploy_link', '/mnt/batch/tasks/shared/LS_root/jobs/lis-ml/azureml/7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/mounts/lis_artifacts/azureml/91420870-1e56-45e9-9039-e85603a441ba/register_deploy_link']\n",
      "\n",
      "lis-gpt2-model version 2\n",
      "2021/08/10 02:52:55 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-08-10 02:52:55+00:00 Creating Container Registry if not exists.\n",
      "2021-08-10 02:52:55+00:00 Registering the environment.\n",
      "2021-08-10 02:52:58+00:00 Use the existing image.\n",
      "2021-08-10 02:52:58+00:00 Generating deployment configuration.\n",
      "2021-08-10 02:52:59+00:00 Submitting deployment to compute..\n",
      "2021-08-10 02:53:08+00:00 Checking the status of deployment lis-gpt2-serviceapp.\n",
      "2021-08-10 02:55:46+00:00 Checking the status of inference endpoint lis-gpt2-serviceapp.\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt\n",
      "===============================================================================================================\n",
      "[2021-08-10T02:56:41.402540] Entering job release\n",
      "[2021-08-10T02:56:42.267566] Starting job release\n",
      "[2021-08-10T02:56:42.268019] Logging experiment finalizing status in history service.\n",
      "[2021-08-10T02:56:42.268188] job release stage : upload_datastore starting...\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 154\n",
      "[2021-08-10T02:56:42.271000] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-08-10T02:56:42.277380] job release stage : execute_job_release starting...\n",
      "[2021-08-10T02:56:42.277936] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-08-10T02:56:42.278056] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-08-10T02:56:42.278661] Entering context manager injector.\n",
      "[2021-08-10T02:56:42.297710] job release stage : upload_datastore completed...\n",
      "[2021-08-10T02:56:42.381042] job release stage : send_run_telemetry starting...\n",
      "[2021-08-10T02:56:42.396464] get vm size and vm region successfully.\n",
      "[2021-08-10T02:56:42.411828] get compute meta data successfully.\n",
      "[2021-08-10T02:56:42.509425] job release stage : execute_job_release completed...\n",
      "[2021-08-10T02:56:42.953241] post artifact meta request successfully.\n",
      "[2021-08-10T02:56:43.011652] upload compute record artifact successfully.\n",
      "[2021-08-10T02:56:43.011725] job release stage : send_run_telemetry completed...\n",
      "[2021-08-10T02:56:43.012011] Job release is complete\n",
      "\n",
      "StepRun(Deploy) Execution Summary\n",
      "==================================\n",
      "StepRun( Deploy ) Status: Finished\n",
      "{'runId': '7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0', 'target': 'pipeline-cluster', 'status': 'Completed', 'startTimeUtc': '2021-08-10T02:52:43.333045Z', 'endTimeUtc': '2021-08-10T02:56:49.657412Z', 'properties': {'ContentSnapshotId': 'f9ae6227-5f97-4b26-87c7-304c3402c618', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '52116e00-bdf2-4f69-93c2-38c8d9179a2e', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '03a9787b', 'azureml.pipelinerunid': 'c61e6022-be86-4993-aaac-02f08f2d3152', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'azureml.RuntimeType': 'Hosttools'}, 'inputDatasets': [], 'outputDatasets': [], 'runDefinition': {'script': 'lis_components/deploy/deploy.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--service_name', '$AML_PARAMETER_aml_service_name', '--model_name', '$AML_PARAMETER_aml_model_name', '--cpu_cores', '$AML_PARAMETER_cpu_cores', '--memory_gb', '$AML_PARAMETER_memory_gb', '--register_deploy_link', '$AZUREML_DATAREFERENCE_register_deploy_link'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'pipeline-cluster', 'dataReferences': {'register_deploy_link': {'dataStoreName': 'lis_artifacts', 'mode': 'Mount', 'pathOnDataStore': 'azureml/91420870-1e56-45e9-9039-e85603a441ba/register_deploy_link', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'pipeline-env', 'version': 'Autosave_2021-08-09T13:40:51Z_738b2e1a', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'dependencies': ['python=3.6.9', 'pip', {'pip': ['transformers == 3.5.1', 'datasets == 1.10.2', 'tensorflow == 2.5.0', 'azureml-defaults==1.30.0']}], 'name': 'azureml_82f5617ca19cd57b18cafd61c017ea7a'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210531.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'AISupercomputer.D2', 'imageVersion': 'pytorch-1.7.0', 'location': 'westus2', 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard'}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {'AML_PARAMETER_aml_service_name': 'lis-gpt2-serviceapp', 'AML_PARAMETER_aml_model_name': 'lis-gpt2-model', 'AML_PARAMETER_cpu_cores': '1', 'AML_PARAMETER_memory_gb': '2'}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/azureml-logs/55_azureml-execution-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt?sv=2019-07-07&sr=b&sig=wQ0MMCkoUH6C2PGQU7bcUd4SsTH8%2BoZQXvNRUm5nWwk%3D&st=2021-08-10T02%3A46%3A44Z&se=2021-08-10T10%3A56%3A44Z&sp=r', 'azureml-logs/65_job_prep-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/azureml-logs/65_job_prep-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt?sv=2019-07-07&sr=b&sig=6ZMvyZbX4MVYudoi%2BGIxBUvOmsu607ziyK%2F9rzYwkRA%3D&st=2021-08-10T02%3A46%3A44Z&se=2021-08-10T10%3A56%3A44Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=Nr3CaKoQxcluUxuiRM%2FhtqUPusX6QnWzSGtXmdoxiDk%3D&st=2021-08-10T02%3A46%3A44Z&se=2021-08-10T10%3A56%3A44Z&sp=r', 'azureml-logs/75_job_post-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/azureml-logs/75_job_post-tvmps_955f2547bd2cda2873762bba399b186e983d2bb1c20a8f2978977ae8fd84a373_d.txt?sv=2019-07-07&sr=b&sig=4PNCnWPaZka6IJjt1erTtJu4SncFpLqNHXrKFO9q%2FwA%3D&st=2021-08-10T02%3A46%3A44Z&se=2021-08-10T10%3A56%3A44Z&sp=r', 'azureml-logs/process_info.json': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/azureml-logs/process_info.json?sv=2019-07-07&sr=b&sig=Ts6r1seg6cI%2FFgltgyB3LuGRcE2nfT4ESzl3iKc%2FJ7Q%3D&st=2021-08-10T02%3A46%3A44Z&se=2021-08-10T10%3A56%3A44Z&sp=r', 'azureml-logs/process_status.json': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/azureml-logs/process_status.json?sv=2019-07-07&sr=b&sig=r9oA6bjBGbqhxfPsCnMbC3nWqTIU0X024k7tJrtUVu4%3D&st=2021-08-10T02%3A46%3A44Z&se=2021-08-10T10%3A56%3A44Z&sp=r', 'logs/azureml/100_azureml.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/logs/azureml/100_azureml.log?sv=2019-07-07&sr=b&sig=HSo6V3tFZ531rSKf1eagEkSKhHIPw2RnK5oMzN2u%2FVc%3D&st=2021-08-10T02%3A46%3A44Z&se=2021-08-10T10%3A56%3A44Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=itvgvFr9QAqoJXGk91RJ4%2FhnBpHP7l2HtFAPhcDdQv0%3D&st=2021-08-10T02%3A46%3A44Z&se=2021-08-10T10%3A56%3A44Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/logs/azureml/job_prep_azureml.log?sv=2019-07-07&sr=b&sig=RQXd%2FnYma5egMMBvKOXxzkMWknVTJf176iG9NEHu204%3D&st=2021-08-10T02%3A46%3A44Z&se=2021-08-10T10%3A56%3A44Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/logs/azureml/job_release_azureml.log?sv=2019-07-07&sr=b&sig=gHnriavDz9KRpYF2rJb9KhyBHpn0R3teLxu%2FwedaswY%3D&st=2021-08-10T02%3A46%3A44Z&se=2021-08-10T10%3A56%3A44Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=vtQ4nyGEPJ%2FhniE%2BokxH0LR3Bs3vn9jTRiGc5T1gmEg%3D&st=2021-08-10T02%3A46%3A44Z&se=2021-08-10T10%3A56%3A44Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.7d10fa18-24d5-4b92-ac0e-5fe5cb2ebec0/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=XEYJqM11kEyJkSL8Te02H%2BAH5U9QlN%2BkFz%2FKLp8iQXU%3D&st=2021-08-10T02%3A46%3A44Z&se=2021-08-10T10%3A56%3A44Z&sp=r'}, 'submittedBy': 'Maggie Mhanna'}\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': 'c61e6022-be86-4993-aaac-02f08f2d3152', 'status': 'Completed', 'startTimeUtc': '2021-08-09T23:40:00.699788Z', 'endTimeUtc': '2021-08-10T02:56:53.920948Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{\"num_train_epochs\":\"10\",\"aml_model_name\":\"lis-gpt2-model\",\"aml_service_name\":\"lis-gpt2-serviceapp\",\"cpu_cores\":\"1\",\"memory_gb\":\"2\"}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.c61e6022-be86-4993-aaac-02f08f2d3152/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=4K1wamHE%2FEbIyjwhkFHOgfJpbXBicP49P%2F1bOXK7bNI%3D&st=2021-08-10T02%3A46%3A55Z&se=2021-08-10T10%3A56%3A55Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.c61e6022-be86-4993-aaac-02f08f2d3152/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=yUTEQB13VsRSlpSCfu1xiPY1dmQtPdeuwbex23FRimA%3D&st=2021-08-10T02%3A46%3A55Z&se=2021-08-10T10%3A56%3A55Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://lisml8132196936.blob.core.windows.net/azureml/ExperimentRun/dcid.c61e6022-be86-4993-aaac-02f08f2d3152/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=fWy%2BsBHAAfct%2FOZ%2FCnBRvaS4dFxaNBa%2BG9YUV6oXVGg%3D&st=2021-08-10T02%3A46%3A55Z&se=2021-08-10T10%3A56%3A55Z&sp=r'}, 'submittedBy': 'Maggie Mhanna'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an experiment and run the pipeline\n",
    "\n",
    "experiment = Experiment(workspace = ws, name = 'lis-ct-pipeline')\n",
    "\n",
    "pipeline_parameters = {\"num_train_epochs\": 10,\n",
    "                       \"aml_model_name\": \"lis-gpt2-model\",\n",
    "                       \"aml_service_name\": \"lis-gpt2-serviceapp\",\n",
    "                       \"cpu_cores\": 1,\n",
    "                       \"memory_gb\": 2,                       \n",
    "                       }\n",
    "\n",
    "pipeline_run = experiment.submit(pipeline, \n",
    "                                 pipeline_parameters=pipeline_parameters)\n",
    "\n",
    "print(\"Pipeline submitted for execution.\")\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccc0b1e",
   "metadata": {},
   "source": [
    "# Consume Web Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75a04c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': \"Hello, let me know that these numbers for this week are accurate. I'm just worried I won't get my deposit back because my checks are too\", '2': \"Hello, The app won't work. Please try again.\", '3': 'Hello you say you have a license yet.\"', '4': 'Hello. It works, but still, I need the address for a specific purchase on my account.', '5': \"Hello? I bought this from a friend earlier today and i think we've definitely exchanged the money and exchanged it!\"}\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "def allowSelfSignedHttps(allowed):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
    "\n",
    "# Request data goes here\n",
    "data = {\"data\": \"Hello\"}\n",
    "\n",
    "body = str.encode(json.dumps(data))\n",
    "\n",
    "url = 'http://a9a4adb6-5d30-4e16-9f7d-e5584c3e4b90.westeurope.azurecontainer.io/score'\n",
    "api_key = '' # Replace this with the API key for the web service\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\n",
    "\n",
    "req = urllib.request.Request(url, body, headers)\n",
    "\n",
    "try:\n",
    "    response = urllib.request.urlopen(req)\n",
    "\n",
    "    result = response.read()\n",
    "    print(json.loads(json.loads(result)))\n",
    "except urllib.error.HTTPError as error:\n",
    "    print(\"The request failed with status code: \" + str(error.code))\n",
    "\n",
    "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
    "    print(error.info())\n",
    "    print(json.loads(error.read().decode(\"utf8\", 'ignore')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c15625e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  :  Hello (I checked and you don't make a payment?)\n",
      "2  :  Hello, I have been looking at my account and it shows a purchase I did not make, as promised. Should you do something please tell me what\n",
      "3  :  Hello? i would like to ask you a question. Can I use the mobile app instead of the desktop because my phone keeps freezing?\n",
      "4  :  Hello. What are you going to do on Monday?\n",
      "5  :  Hello. I made a payment on transfer and suddenly my account is transferred to an app! Please help me.  I wouldn't have done that\n"
     ]
    }
   ],
   "source": [
    "result_dict = json.loads(json.loads(result))\n",
    "for key in result_dict:\n",
    "    print(key, ' : ', result_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dff2e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
